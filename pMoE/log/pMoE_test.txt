initialized the distributed DNN
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  4.04it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  4.11it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  3.90it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  3.90it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.04it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.86it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.20it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.00it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.90it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.71it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.92it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.73it/s]
Wrapping layer 0 / 22 from mlp to pMoE
WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:108: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate = torch.load(f"{weight_path}/layer_{i}_gate.pt").to(gpu_idx)

W0108 18:30:14.365026 49500 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:108: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate = torch.load(f"{weight_path}/layer_{i}_gate.pt").to(gpu_idx)

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:108: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate = torch.load(f"{weight_path}/layer_{i}_gate.pt").to(gpu_idx)

W0108 18:30:14.393567 49499 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:108: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate = torch.load(f"{weight_path}/layer_{i}_gate.pt").to(gpu_idx)

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:108: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate = torch.load(f"{weight_path}/layer_{i}_gate.pt").to(gpu_idx)

W0108 18:30:14.459433 49502 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:108: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate = torch.load(f"{weight_path}/layer_{i}_gate.pt").to(gpu_idx)

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:108: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate = torch.load(f"{weight_path}/layer_{i}_gate.pt").to(gpu_idx)

W0108 18:30:14.703603 49501 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:108: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate = torch.load(f"{weight_path}/layer_{i}_gate.pt").to(gpu_idx)

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:127: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  w1 = torch.load(f"{weight_path}/layer_{i}_expert_{expert_idx}_w1.pt")

W0108 18:30:14.743520 49499 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:127: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  w1 = torch.load(f"{weight_path}/layer_{i}_expert_{expert_idx}_w1.pt")

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:128: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  w2 = torch.load(f"{weight_path}/layer_{i}_expert_{expert_idx}_w2.pt")

W0108 18:30:14.763413 49499 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:128: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  w2 = torch.load(f"{weight_path}/layer_{i}_expert_{expert_idx}_w2.pt")

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:129: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  w3 = torch.load(f"{weight_path}/layer_{i}_expert_{expert_idx}_w3.pt")

W0108 18:30:14.769279 49499 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:129: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  w3 = torch.load(f"{weight_path}/layer_{i}_expert_{expert_idx}_w3.pt")

Wrapping layer 1 / 22 from mlp to pMoE
WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:127: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  w1 = torch.load(f"{weight_path}/layer_{i}_expert_{expert_idx}_w1.pt")

W0108 18:30:15.553009 49500 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:127: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  w1 = torch.load(f"{weight_path}/layer_{i}_expert_{expert_idx}_w1.pt")

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:128: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  w2 = torch.load(f"{weight_path}/layer_{i}_expert_{expert_idx}_w2.pt")

W0108 18:30:15.569703 49500 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:128: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  w2 = torch.load(f"{weight_path}/layer_{i}_expert_{expert_idx}_w2.pt")

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:129: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  w3 = torch.load(f"{weight_path}/layer_{i}_expert_{expert_idx}_w3.pt")

W0108 18:30:15.575215 49500 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:129: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  w3 = torch.load(f"{weight_path}/layer_{i}_expert_{expert_idx}_w3.pt")

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:127: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  w1 = torch.load(f"{weight_path}/layer_{i}_expert_{expert_idx}_w1.pt")

W0108 18:30:15.590186 49502 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:127: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  w1 = torch.load(f"{weight_path}/layer_{i}_expert_{expert_idx}_w1.pt")

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:128: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  w2 = torch.load(f"{weight_path}/layer_{i}_expert_{expert_idx}_w2.pt")

W0108 18:30:15.608984 49502 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:128: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  w2 = torch.load(f"{weight_path}/layer_{i}_expert_{expert_idx}_w2.pt")

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:129: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  w3 = torch.load(f"{weight_path}/layer_{i}_expert_{expert_idx}_w3.pt")

W0108 18:30:15.616652 49502 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:129: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  w3 = torch.load(f"{weight_path}/layer_{i}_expert_{expert_idx}_w3.pt")

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:127: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  w1 = torch.load(f"{weight_path}/layer_{i}_expert_{expert_idx}_w1.pt")

W0108 18:30:15.676622 49501 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:127: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  w1 = torch.load(f"{weight_path}/layer_{i}_expert_{expert_idx}_w1.pt")

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:128: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  w2 = torch.load(f"{weight_path}/layer_{i}_expert_{expert_idx}_w2.pt")

W0108 18:30:15.697229 49501 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:128: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  w2 = torch.load(f"{weight_path}/layer_{i}_expert_{expert_idx}_w2.pt")

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:129: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  w3 = torch.load(f"{weight_path}/layer_{i}_expert_{expert_idx}_w3.pt")

W0108 18:30:15.715930 49501 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:129: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  w3 = torch.load(f"{weight_path}/layer_{i}_expert_{expert_idx}_w3.pt")

Wrapping layer 2 / 22 from mlp to pMoE
Wrapping layer 3 / 22 from mlp to pMoE
Wrapping layer 4 / 22 from mlp to pMoE
Wrapping layer 5 / 22 from mlp to pMoE
Wrapping layer 6 / 22 from mlp to pMoE
Wrapping layer 7 / 22 from mlp to pMoE
Wrapping layer 8 / 22 from mlp to pMoE
Wrapping layer 9 / 22 from mlp to pMoE
Wrapping layer 10 / 22 from mlp to pMoE
Wrapping layer 11 / 22 from mlp to pMoE
Wrapping layer 12 / 22 from mlp to pMoE
Wrapping layer 13 / 22 from mlp to pMoE
Wrapping layer 14 / 22 from mlp to pMoE
Wrapping layer 15 / 22 from mlp to pMoE
Wrapping layer 16 / 22 from mlp to pMoE
Wrapping layer 17 / 22 from mlp to pMoE
Wrapping layer 18 / 22 from mlp to pMoE
Wrapping layer 19 / 22 from mlp to pMoE
Wrapping layer 20 / 22 from mlp to pMoE
Wrapping layer 21 / 22 from mlp to pMoE
processing 0th data
processing 10th data
processing 20th data
processing 30th data
processing 40th data
processing 50th data
processing 60th data
processing 70th data
processing 80th data
processing 90th data
processing 100th data
processing 110th data
processing 120th data
processing 130th data
processing 140th data
processing 150th data
processing 160th data
processing 170th data
processing 180th data
processing 190th data
processing 200th data
processing 210th data
processing 220th data
processing 230th data
processing 240th data
processing 250th data
processing 260th data
processing 270th data
processing 280th data
processing 290th data
processing 300th data
processing 310th data
processing 320th data
processing 330th data
processing 340th data
processing 350th data
processing 360th data
processing 370th data
processing 380th data
processing 390th data
processing 400th data
processing 410th data
processing 420th data
processing 430th data
processing 440th data
processing 450th data
processing 460th data
processing 470th data
processing 480th data
processing 490th data
processing 500th data
processing 510th data
processing 520th data
processing 530th data
processing 540th data
processing 550th data
processing 560th data
processing 570th data
processing 580th data
processing 590th data
processing 600th data
processing 610th data
processing 620th data
processing 630th data
processing 640th data
processing 650th data
processing 660th data
processing 670th data
processing 680th data
processing 690th data
processing 700th data
processing 710th data
processing 720th data
processing 730th data
processing 740th data
processing 750th data
processing 760th data
processing 770th data
processing 780th data
processing 790th data
processing 800th data
processing 810th data
processing 820th data
processing 830th data
processing 840th data
processing 850th data
processing 860th data
processing 870th data
processing 880th data
processing 890th data
processing 900th data
processing 910th data
processing 920th data
processing 930th data
processing 940th data
processing 950th data
processing 960th data
processing 970th data
processing 980th data
processing 990th data
processing 1000th data
processing 1010th data
processing 1020th data
processing 1030th data
processing 1040th data
processing 1050th data
processing 1060th data
processing 1070th data
processing 1080th data
processing 1090th data
processing 1100th data
processing 1110th data
processing 1120th data
processing 1130th data
processing 1140th data
processing 1150th data
processing 1160th data
processing 1170th data
processing 1180th data
processing 1190th data
processing 1200th data
processing 1210th data
processing 1220th data
processing 1230th data
processing 1240th data
processing 1250th data
processing 1260th data
processing 1270th data
processing 1280th data
processing 1290th data
processing 1300th data
processing 1310th data
processing 1320th data
processing 1330th data
processing 1340th data
processing 1350th data
processing 1360th data
processing 1370th data
processing 1380th data
processing 1390th data
processing 1400th data
processing 1410th data
processing 1420th data
processing 1430th data
processing 1440th data
processing 1450th data
processing 1460th data
processing 1470th data
processing 1480th data
processing 1490th data
processing 1500th data
processing 1510th data
processing 1520th data
processing 1530th data
processing 1540th data
processing 1550th data
processing 1560th data
processing 1570th data
processing 1580th data
processing 1590th data
processing 1600th data
processing 1610th data
processing 1620th data
processing 1630th data
processing 1640th data
processing 1650th data
processing 1660th data
processing 1670th data
processing 1680th data
processing 1690th data
processing 1700th data
processing 1710th data
processing 1720th data
processing 1730th data
processing 1740th data
processing 1750th data
processing 1760th data
processing 1770th data
processing 1780th data
processing 1790th data
processing 1800th data
processing 1810th data
processing 1820th data
processing 1830th data
processing 1840th data
processing 1850th data
processing 1860th data
processing 1870th data
processing 1880th data
processing 1890th data
processing 1900th data
processing 1910th data
processing 1920th data
processing 1930th data
processing 1940th data
processing 1950th data
processing 1960th data
processing 1970th data
processing 1980th data
processing 1990th data
processing 2000th data
processing 2010th data
processing 2020th data
processing 2030th data
processing 2040th data
processing 2050th data
processing 2060th data
processing 2070th data
processing 2080th data
processing 2090th data
processing 2100th data
processing 2110th data
processing 2120th data
processing 2130th data
processing 2140th data
processing 2150th data
processing 2160th data
processing 2170th data
processing 2180th data
processing 2190th data
processing 2200th data
processing 2210th data
processing 2220th data
processing 2230th data
processing 2240th data
processing 2250th data
processing 2260th data
processing 2270th data
processing 2280th data
processing 2290th data
processing 2300th data
processing 2310th data
processing 2320th data
processing 2330th data
processing 2340th data
processing 2350th data
processing 2360th data
processing 2370th data
processing 2380th data
processing 2390th data
processing 2400th data
processing 2410th data
processing 2420th data
processing 2430th data
processing 2440th data
processing 2450th data
processing 2460th data
processing 2470th data
processing 2480th data
processing 2490th data
processing 2500th data
processing 2510th data
processing 2520th data
processing 2530th data
processing 2540th data
processing 2550th data
processing 2560th data
processing 2570th data
processing 2580th data
processing 2590th data
processing 2600th data
processing 2610th data
processing 2620th data
processing 2630th data
processing 2640th data
processing 2650th data
processing 2660th data
processing 2670th data
processing 2680th data
processing 2690th data
processing 2700th data
processing 2710th data
processing 2720th data
processing 2730th data
processing 2740th data
processing 2750th data
processing 2760th data
processing 2770th data
processing 2780th data
processing 2790th data
processing 2800th data
processing 2810th data
processing 2820th data
processing 2830th data
processing 2840th data
processing 2850th data
processing 2860th data
processing 2870th data
processing 2880th data
processing 2890th data
processing 2900th data
processing 2910th data
processing 2920th data
processing 2930th data
processing 2940th data
processing 2950th data
processing 2960th data
processing 2970th data
processing 2980th data
processing 2990th data
processing 3000th data
processing 3010th data
processing 3020th data
processing 3030th data
processing 3040th data
processing 3050th data
processing 3060th data
processing 3070th data
processing 3080th data
processing 3090th data
processing 3100th data
processing 3110th data
processing 3120th data
processing 3130th data
processing 3140th data
processing 3150th data
processing 3160th data
processing 3170th data
processing 3180th data
processing 3190th data
processing 3200th data
processing 3210th data
processing 3220th data
processing 3230th data
processing 3240th data
processing 3250th data
processing 3260th data
processing 3270th data
processing 3280th data
processing 3290th data
processing 3300th data
processing 3310th data
processing 3320th data
processing 3330th data
processing 3340th data
processing 3350th data
processing 3360th data
processing 3370th data
processing 3380th data
processing 3390th data
processing 3400th data
processing 3410th data
processing 3420th data
processing 3430th data
processing 3440th data
processing 3450th data
processing 3460th data
processing 3470th data
processing 3480th data
processing 3490th data
processing 3500th data
processing 3510th data
processing 3520th data
processing 3530th data
processing 3540th data
processing 3550th data
processing 3560th data
processing 3570th data
processing 3580th data
processing 3590th data
processing 3600th data
processing 3610th data
processing 3620th data
processing 3630th data
processing 3640th data
processing 3650th data
processing 3660th data
processing 3670th data
processing 3680th data
processing 3690th data
processing 3700th data
processing 3710th data
processing 3720th data
processing 3730th data
processing 3740th data
processing 3750th data
processing 3760th data
processing 3770th data
processing 3780th data
processing 3790th data
processing 3800th data
processing 3810th data
processing 3820th data
processing 3830th data
processing 3840th data
processing 3850th data
processing 3860th data
processing 3870th data
processing 3880th data
processing 3890th data
processing 3900th data
processing 3910th data
processing 3920th data
processing 3930th data
processing 3940th data
processing 3950th data
processing 3960th data
processing 3970th data
processing 3980th data
processing 3990th data
processing 4000th data
processing 4010th data
processing 4020th data
processing 4030th data
processing 4040th data
processing 4050th data
processing 4060th data
processing 4070th data
processing 4080th data
processing 4090th data
processing 4100th data
processing 4110th data
processing 4120th data
processing 4130th data
processing 4140th data
processing 4150th data
processing 4160th data
processing 4170th data
processing 4180th data
processing 4190th data
processing 4200th data
processing 4210th data
processing 4220th data
processing 4230th data
processing 4240th data
processing 4250th data
processing 4260th data
processing 4270th data
processing 4280th data
processing 4290th data
processing 4300th data
processing 4310th data
processing 4320th data
processing 4330th data
processing 4340th data
processing 4350th data
processing 4360th data
processing 4370th data
processing 4380th data
processing 4390th data
processing 4400th data
processing 4410th data
processing 4420th data
processing 4430th data
processing 4440th data
processing 4450th data
processing 4460th data
processing 4470th data
processing 4480th data
processing 4490th data
processing 4500th data
processing 4510th data
processing 4520th data
processing 4530th data
processing 4540th data
processing 4550th data
processing 4560th data
processing 4570th data
processing 4580th data
processing 4590th data
processing 4600th data
processing 4610th data
processing 4620th data
processing 4630th data
processing 4640th data
processing 4650th data
processing 4660th data
processing 4670th data
processing 4680th data
processing 4690th data
processing 4700th data
processing 4710th data
processing 4720th data
processing 4730th data
processing 4740th data
processing 4750th data
processing 4760th data
processing 4770th data
processing 4780th data
processing 4790th data
processing 4800th data
processing 4810th data
processing 4820th data
processing 4830th data
processing 4840th data
processing 4850th data
processing 4860th data
processing 4870th data
processing 4880th data
processing 4890th data
processing 4900th data
processing 4910th data
processing 4920th data
processing 4930th data
processing 4940th data
processing 4950th data
processing 4960th data
processing 4970th data
processing 4980th data
processing 4990th data
processing 5000th data
processing 5010th data
processing 5020th data
processing 5030th data
processing 5040th data
processing 5050th data
processing 5060th data
processing 5070th data
processing 5080th data
processing 5090th data
processing 5100th data
processing 5110th data
processing 5120th data
processing 5130th data
processing 5140th data
processing 5150th data
processing 5160th data
processing 5170th data
processing 5180th data
processing 5190th data
processing 5200th data
processing 5210th data
processing 5220th data
processing 5230th data
processing 5240th data
processing 5250th data
processing 5260th data
processing 5270th data
processing 5280th data
processing 5290th data
processing 5300th data
processing 5310th data
processing 5320th data
processing 5330th data
processing 5340th data
processing 5350th data
processing 5360th data
processing 5370th data
processing 5380th data
processing 5390th data
processing 5400th data
processing 5410th data
processing 5420th data
processing 5430th data
processing 5440th data
processing 5450th data
processing 5460th data
processing 5470th data
processing 5480th data
processing 5490th data
processing 5500th data
processing 5510th data
processing 5520th data
processing 5530th data
processing 5540th data
processing 5550th data
processing 5560th data
processing 5570th data
processing 5580th data
processing 5590th data
processing 5600th data
processing 5610th data
processing 5620th data
processing 5630th data
processing 5640th data
processing 5650th data
processing 5660th data
processing 5670th data
processing 5680th data
processing 5690th data
processing 5700th data
processing 5710th data
processing 5720th data
processing 5730th data
processing 5740th data
processing 5750th data
processing 5760th data
processing 5770th data
processing 5780th data
processing 5790th data
processing 5800th data
processing 5810th data
processing 5820th data
processing 5830th data
processing 5840th data
processing 5850th data
processing 5860th data
processing 5870th data
processing 5880th data
processing 5890th data
processing 5900th data
processing 5910th data
processing 5920th data
processing 5930th data
processing 5940th data
processing 5950th data
processing 5960th data
processing 5970th data
processing 5980th data
processing 5990th data
processing 6000th data
processing 6010th data
processing 6020th data
processing 6030th data
processing 6040th data
processing 6050th data
processing 6060th data
processing 6070th data
processing 6080th data
processing 6090th data
processing 6100th data
processing 6110th data
processing 6120th data
processing 6130th data
processing 6140th data
processing 6150th data
processing 6160th data
processing 6170th data
processing 6180th data
processing 6190th data
processing 6200th data
processing 6210th data
processing 6220th data
processing 6230th data
processing 6240th data
processing 6250th data
processing 6260th data
processing 6270th data
processing 6280th data
processing 6290th data
processing 6300th data
processing 6310th data
processing 6320th data
processing 6330th data
processing 6340th data
processing 6350th data
processing 6360th data
processing 6370th data
processing 6380th data
processing 6390th data
processing 6400th data
processing 6410th data
processing 6420th data
processing 6430th data
processing 6440th data
processing 6450th data
processing 6460th data
processing 6470th data
processing 6480th data
processing 6490th data
processing 6500th data
processing 6510th data
processing 6520th data
processing 6530th data
processing 6540th data
processing 6550th data
processing 6560th data
processing 6570th data
processing 6580th data
processing 6590th data
processing 6600th data
processing 6610th data
processing 6620th data
processing 6630th data
processing 6640th data
processing 6650th data
processing 6660th data
processing 6670th data
processing 6680th data
processing 6690th data
processing 6700th data
processing 6710th data
processing 6720th data
processing 6730th data
processing 6740th data
processing 6750th data
processing 6760th data
processing 6770th data
processing 6780th data
processing 6790th data
processing 6800th data
processing 6810th data
processing 6820th data
processing 6830th data
processing 6840th data
processing 6850th data
processing 6860th data
processing 6870th data
processing 6880th data
processing 6890th data
processing 6900th data
processing 6910th data
processing 6920th data
processing 6930th data
processing 6940th data
processing 6950th data
processing 6960th data
processing 6970th data
processing 6980th data
processing 6990th data
processing 7000th data
processing 7010th data
processing 7020th data
processing 7030th data
processing 7040th data
processing 7050th data
processing 7060th data
processing 7070th data
processing 7080th data
processing 7090th data
processing 7100th data
processing 7110th data
processing 7120th data
processing 7130th data
processing 7140th data
processing 7150th data
processing 7160th data
processing 7170th data
processing 7180th data
processing 7190th data
processing 7200th data
processing 7210th data
processing 7220th data
processing 7230th data
processing 7240th data
processing 7250th data
processing 7260th data
processing 7270th data
processing 7280th data
processing 7290th data
processing 7300th data
processing 7310th data
processing 7320th data
processing 7330th data
processing 7340th data
processing 7350th data
processing 7360th data
processing 7370th data
processing 7380th data
processing 7390th data
processing 7400th data
processing 7410th data
processing 7420th data
processing 7430th data
processing 7440th data
processing 7450th data
processing 7460th data
processing 7470th data
processing 7480th data
processing 7490th data
processing 7500th data
processing 7510th data
processing 7520th data
processing 7530th data
processing 7540th data
processing 7550th data
processing 7560th data
processing 7570th data
processing 7580th data
processing 7590th data
processing 7600th data
processing 7610th data
processing 7620th data
processing 7630th data
processing 7640th data
processing 7650th data
processing 7660th data
processing 7670th data
processing 7680th data
processing 7690th data
processing 7700th data
processing 7710th data
processing 7720th data
processing 7730th data
processing 7740th data
processing 7750th data
processing 7760th data
processing 7770th data
processing 7780th data
processing 7790th data
processing 7800th data
processing 7810th data
processing 7820th data
processing 7830th data
processing 7840th data
processing 7850th data
processing 7860th data
processing 7870th data
processing 7880th data
processing 7890th data
processing 7900th data
processing 7910th data
processing 7920th data
processing 7930th data
processing 7940th data
processing 7950th data
processing 7960th data
processing 7970th data
processing 7980th data
processing 7990th data
processing 8000th data
processing 8010th data
processing 8020th data
processing 8030th data
processing 8040th data
processing 8050th data
processing 8060th data
processing 8070th data
processing 8080th data
processing 8090th data
processing 8100th data
processing 8110th data
processing 8120th data
processing 8130th data
processing 8140th data
processing 8150th data
processing 8160th data
processing 8170th data
processing 8180th data
processing 8190th data
processing 8200th data
processing 8210th data
processing 8220th data
processing 8230th data
processing 8240th data
processing 8250th data
processing 8260th data
processing 8270th data
processing 8280th data
processing 8290th data
processing 8300th data
processing 8310th data
processing 8320th data
processing 8330th data
processing 8340th data
processing 8350th data
processing 8360th data
processing 8370th data
processing 8380th data
processing 8390th data
processing 8400th data
processing 8410th data
processing 8420th data
processing 8430th data
processing 8440th data
processing 8450th data
processing 8460th data
processing 8470th data
processing 8480th data
processing 8490th data
processing 8500th data
processing 8510th data
processing 8520th data
processing 8530th data
processing 8540th data
processing 8550th data
processing 8560th data
processing 8570th data
processing 8580th data
processing 8590th data
processing 8600th data
processing 8610th data
processing 8620th data
processing 8630th data
processing 8640th data
processing 8650th data
processing 8660th data
processing 8670th data
processing 8680th data
processing 8690th data
processing 8700th data
processing 8710th data
processing 8720th data
processing 8730th data
processing 8740th data
processing 8750th data
processing 8760th data
processing 8770th data
processing 8780th data
processing 8790th data
processing 8800th data
processing 8810th data
processing 8820th data
processing 8830th data
processing 8840th data
processing 8850th data
processing 8860th data
processing 8870th data
processing 8880th data
processing 8890th data
processing 8900th data
processing 8910th data
processing 8920th data
processing 8930th data
processing 8940th data
processing 8950th data
processing 8960th data
processing 8970th data
processing 8980th data
processing 8990th data
processing 9000th data
processing 9010th data
processing 9020th data
processing 9030th data
processing 9040th data
processing 9050th data
processing 9060th data
processing 9070th data
processing 9080th data
processing 9090th data
processing 9100th data
processing 9110th data
processing 9120th data
processing 9130th data
processing 9140th data
processing 9150th data
processing 9160th data
processing 9170th data
processing 9180th data
processing 9190th data
processing 9200th data
processing 9210th data
processing 9220th data
processing 9230th data
processing 9240th data
processing 9250th data
processing 9260th data
processing 9270th data
processing 9280th data
processing 9290th data
processing 9300th data
processing 9310th data
processing 9320th data
processing 9330th data
processing 9340th data
processing 9350th data
processing 9360th data
processing 9370th data
processing 9380th data
processing 9390th data
processing 9400th data
processing 9410th data
processing 9420th data
processing 9430th data
processing 9440th data
processing 9450th data
processing 9460th data
processing 9470th data
processing 9480th data
processing 9490th data
processing 9500th data
processing 9510th data
processing 9520th data
processing 9530th data
processing 9540th data
processing 9550th data
processing 9560th data
processing 9570th data
processing 9580th data
processing 9590th data
processing 9600th data
processing 9610th data
processing 9620th data
processing 9630th data
processing 9640th data
processing 9650th data
processing 9660th data
processing 9670th data
processing 9680th data
processing 9690th data
processing 9700th data
processing 9710th data
processing 9720th data
processing 9730th data
processing 9740th data
processing 9750th data
processing 9760th data
processing 9770th data
processing 9780th data
processing 9790th data
processing 9800th data
processing 9810th data
processing 9820th data
processing 9830th data
processing 9840th data
processing 9850th data
processing 9860th data
processing 9870th data
processing 9880th data
processing 9890th data
processing 9900th data
processing 9910th data
processing 9920th data
processing 9930th data
processing 9940th data
processing 9950th data
processing 9960th data
processing 9970th data
processing 9980th data
processing 9990th data
processing 10000th data
PMOE: [Rank 3] Average Elapsed Time: 54.68081315689087 ms 

PMOE: [Rank 2] Average Elapsed Time: 54.677082098007205 ms 

PMOE: [Rank 0] Average Elapsed Time: 54.669665983200076 ms 

PMOE: [Rank 1] Average Elapsed Time: 54.67990610809326 ms 

gpuidx: 3 with rank: 3 with world size: 4
gpuidx: 0 with rank: 0 with world size: 4
initialized the distributed DNN
gpuidx: 2 with rank: 2 with world size: 4
gpuidx: 1 with rank: 1 with world size: 4
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  4.00it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  3.85it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  2.96it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  3.11it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.03it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.84it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.83it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.65it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.54it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.44it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.83it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.70it/s]
Wrapping layer 0 / 22 from mlp to fMoE
WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:164: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate = torch.load(f"{weight_path}/layer_{i}_gate.pt").to(gpu_idx)

W0108 18:40:09.318907 49501 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:164: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate = torch.load(f"{weight_path}/layer_{i}_gate.pt").to(gpu_idx)

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:164: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate = torch.load(f"{weight_path}/layer_{i}_gate.pt").to(gpu_idx)

W0108 18:40:09.334923 49499 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:164: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate = torch.load(f"{weight_path}/layer_{i}_gate.pt").to(gpu_idx)

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:164: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate = torch.load(f"{weight_path}/layer_{i}_gate.pt").to(gpu_idx)

W0108 18:40:09.552197 49500 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:164: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate = torch.load(f"{weight_path}/layer_{i}_gate.pt").to(gpu_idx)

Wrapping layer 1 / 22 from mlp to fMoE
WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:164: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate = torch.load(f"{weight_path}/layer_{i}_gate.pt").to(gpu_idx)

W0108 18:40:09.808624 49502 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:164: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate = torch.load(f"{weight_path}/layer_{i}_gate.pt").to(gpu_idx)

Wrapping layer 2 / 22 from mlp to fMoE
Wrapping layer 3 / 22 from mlp to fMoE
Wrapping layer 4 / 22 from mlp to fMoE
Wrapping layer 5 / 22 from mlp to fMoE
Wrapping layer 6 / 22 from mlp to fMoE
Wrapping layer 7 / 22 from mlp to fMoE
Wrapping layer 8 / 22 from mlp to fMoE
Wrapping layer 9 / 22 from mlp to fMoE
Wrapping layer 10 / 22 from mlp to fMoE
Wrapping layer 11 / 22 from mlp to fMoE
Wrapping layer 12 / 22 from mlp to fMoE
Wrapping layer 13 / 22 from mlp to fMoE
Wrapping layer 14 / 22 from mlp to fMoE
Wrapping layer 15 / 22 from mlp to fMoE
Wrapping layer 16 / 22 from mlp to fMoE
Wrapping layer 17 / 22 from mlp to fMoE
Wrapping layer 18 / 22 from mlp to fMoE
Wrapping layer 19 / 22 from mlp to fMoE
Wrapping layer 20 / 22 from mlp to fMoE
Wrapping layer 21 / 22 from mlp to fMoE
processing 0th data
processing 10th data
processing 20th data
processing 30th data
processing 40th data
processing 50th data
processing 60th data
processing 70th data
processing 80th data
processing 90th data
processing 100th data
processing 110th data
processing 120th data
processing 130th data
processing 140th data
processing 150th data
processing 160th data
processing 170th data
processing 180th data
processing 190th data
processing 200th data
processing 210th data
processing 220th data
processing 230th data
processing 240th data
processing 250th data
processing 260th data
processing 270th data
processing 280th data
processing 290th data
processing 300th data
processing 310th data
processing 320th data
processing 330th data
processing 340th data
processing 350th data
processing 360th data
processing 370th data
processing 380th data
processing 390th data
processing 400th data
processing 410th data
processing 420th data
processing 430th data
processing 440th data
processing 450th data
processing 460th data
processing 470th data
processing 480th data
processing 490th data
processing 500th data
processing 510th data
processing 520th data
processing 530th data
processing 540th data
processing 550th data
processing 560th data
processing 570th data
processing 580th data
processing 590th data
processing 600th data
processing 610th data
processing 620th data
processing 630th data
processing 640th data
processing 650th data
processing 660th data
processing 670th data
processing 680th data
processing 690th data
processing 700th data
processing 710th data
processing 720th data
processing 730th data
processing 740th data
processing 750th data
processing 760th data
processing 770th data
processing 780th data
processing 790th data
processing 800th data
processing 810th data
processing 820th data
processing 830th data
processing 840th data
processing 850th data
processing 860th data
processing 870th data
processing 880th data
processing 890th data
processing 900th data
processing 910th data
processing 920th data
processing 930th data
processing 940th data
processing 950th data
processing 960th data
processing 970th data
processing 980th data
processing 990th data
processing 1000th data
processing 1010th data
processing 1020th data
processing 1030th data
processing 1040th data
processing 1050th data
processing 1060th data
processing 1070th data
processing 1080th data
processing 1090th data
processing 1100th data
processing 1110th data
processing 1120th data
processing 1130th data
processing 1140th data
processing 1150th data
processing 1160th data
processing 1170th data
processing 1180th data
processing 1190th data
processing 1200th data
processing 1210th data
processing 1220th data
processing 1230th data
processing 1240th data
processing 1250th data
processing 1260th data
processing 1270th data
processing 1280th data
processing 1290th data
processing 1300th data
processing 1310th data
processing 1320th data
processing 1330th data
processing 1340th data
processing 1350th data
processing 1360th data
processing 1370th data
processing 1380th data
processing 1390th data
processing 1400th data
processing 1410th data
processing 1420th data
processing 1430th data
processing 1440th data
processing 1450th data
processing 1460th data
processing 1470th data
processing 1480th data
processing 1490th data
processing 1500th data
processing 1510th data
processing 1520th data
processing 1530th data
processing 1540th data
processing 1550th data
processing 1560th data
processing 1570th data
processing 1580th data
processing 1590th data
processing 1600th data
processing 1610th data
processing 1620th data
processing 1630th data
processing 1640th data
processing 1650th data
processing 1660th data
processing 1670th data
processing 1680th data
processing 1690th data
processing 1700th data
processing 1710th data
processing 1720th data
processing 1730th data
processing 1740th data
processing 1750th data
processing 1760th data
processing 1770th data
processing 1780th data
processing 1790th data
processing 1800th data
processing 1810th data
processing 1820th data
processing 1830th data
processing 1840th data
processing 1850th data
processing 1860th data
processing 1870th data
processing 1880th data
processing 1890th data
processing 1900th data
processing 1910th data
processing 1920th data
processing 1930th data
processing 1940th data
processing 1950th data
processing 1960th data
processing 1970th data
processing 1980th data
processing 1990th data
processing 2000th data
processing 2010th data
processing 2020th data
processing 2030th data
processing 2040th data
processing 2050th data
processing 2060th data
processing 2070th data
processing 2080th data
processing 2090th data
processing 2100th data
processing 2110th data
processing 2120th data
processing 2130th data
processing 2140th data
processing 2150th data
processing 2160th data
processing 2170th data
processing 2180th data
processing 2190th data
processing 2200th data
processing 2210th data
processing 2220th data
processing 2230th data
processing 2240th data
processing 2250th data
processing 2260th data
processing 2270th data
processing 2280th data
processing 2290th data
processing 2300th data
processing 2310th data
processing 2320th data
processing 2330th data
processing 2340th data
processing 2350th data
processing 2360th data
processing 2370th data
processing 2380th data
processing 2390th data
processing 2400th data
processing 2410th data
processing 2420th data
processing 2430th data
processing 2440th data
processing 2450th data
processing 2460th data
processing 2470th data
processing 2480th data
processing 2490th data
processing 2500th data
processing 2510th data
processing 2520th data
processing 2530th data
processing 2540th data
processing 2550th data
processing 2560th data
processing 2570th data
processing 2580th data
processing 2590th data
processing 2600th data
processing 2610th data
processing 2620th data
processing 2630th data
processing 2640th data
processing 2650th data
processing 2660th data
processing 2670th data
processing 2680th data
processing 2690th data
processing 2700th data
processing 2710th data
processing 2720th data
processing 2730th data
processing 2740th data
processing 2750th data
processing 2760th data
processing 2770th data
processing 2780th data
processing 2790th data
processing 2800th data
processing 2810th data
processing 2820th data
processing 2830th data
processing 2840th data
processing 2850th data
processing 2860th data
processing 2870th data
processing 2880th data
processing 2890th data
processing 2900th data
processing 2910th data
processing 2920th data
processing 2930th data
processing 2940th data
processing 2950th data
processing 2960th data
processing 2970th data
processing 2980th data
processing 2990th data
processing 3000th data
processing 3010th data
processing 3020th data
processing 3030th data
processing 3040th data
processing 3050th data
processing 3060th data
processing 3070th data
processing 3080th data
processing 3090th data
processing 3100th data
processing 3110th data
processing 3120th data
processing 3130th data
processing 3140th data
processing 3150th data
processing 3160th data
processing 3170th data
processing 3180th data
processing 3190th data
processing 3200th data
processing 3210th data
processing 3220th data
processing 3230th data
processing 3240th data
processing 3250th data
processing 3260th data
processing 3270th data
processing 3280th data
processing 3290th data
processing 3300th data
processing 3310th data
processing 3320th data
processing 3330th data
processing 3340th data
processing 3350th data
processing 3360th data
processing 3370th data
processing 3380th data
processing 3390th data
processing 3400th data
processing 3410th data
processing 3420th data
processing 3430th data
processing 3440th data
processing 3450th data
processing 3460th data
processing 3470th data
processing 3480th data
processing 3490th data
processing 3500th data
processing 3510th data
processing 3520th data
processing 3530th data
processing 3540th data
processing 3550th data
processing 3560th data
processing 3570th data
processing 3580th data
processing 3590th data
processing 3600th data
processing 3610th data
processing 3620th data
processing 3630th data
processing 3640th data
processing 3650th data
processing 3660th data
processing 3670th data
processing 3680th data
processing 3690th data
processing 3700th data
processing 3710th data
processing 3720th data
processing 3730th data
processing 3740th data
processing 3750th data
processing 3760th data
processing 3770th data
processing 3780th data
processing 3790th data
processing 3800th data
processing 3810th data
processing 3820th data
processing 3830th data
processing 3840th data
processing 3850th data
processing 3860th data
processing 3870th data
processing 3880th data
processing 3890th data
processing 3900th data
processing 3910th data
processing 3920th data
processing 3930th data
processing 3940th data
processing 3950th data
processing 3960th data
processing 3970th data
processing 3980th data
processing 3990th data
processing 4000th data
processing 4010th data
processing 4020th data
processing 4030th data
processing 4040th data
processing 4050th data
processing 4060th data
processing 4070th data
processing 4080th data
processing 4090th data
processing 4100th data
processing 4110th data
processing 4120th data
processing 4130th data
processing 4140th data
processing 4150th data
processing 4160th data
processing 4170th data
processing 4180th data
processing 4190th data
processing 4200th data
processing 4210th data
processing 4220th data
processing 4230th data
processing 4240th data
processing 4250th data
processing 4260th data
processing 4270th data
processing 4280th data
processing 4290th data
processing 4300th data
processing 4310th data
processing 4320th data
processing 4330th data
processing 4340th data
processing 4350th data
processing 4360th data
processing 4370th data
processing 4380th data
processing 4390th data
processing 4400th data
processing 4410th data
processing 4420th data
processing 4430th data
processing 4440th data
processing 4450th data
processing 4460th data
processing 4470th data
processing 4480th data
processing 4490th data
processing 4500th data
processing 4510th data
processing 4520th data
processing 4530th data
processing 4540th data
processing 4550th data
processing 4560th data
processing 4570th data
processing 4580th data
processing 4590th data
processing 4600th data
processing 4610th data
processing 4620th data
processing 4630th data
processing 4640th data
processing 4650th data
processing 4660th data
processing 4670th data
processing 4680th data
processing 4690th data
processing 4700th data
processing 4710th data
processing 4720th data
processing 4730th data
processing 4740th data
processing 4750th data
processing 4760th data
processing 4770th data
processing 4780th data
processing 4790th data
processing 4800th data
processing 4810th data
processing 4820th data
processing 4830th data
processing 4840th data
processing 4850th data
processing 4860th data
processing 4870th data
processing 4880th data
processing 4890th data
processing 4900th data
processing 4910th data
processing 4920th data
processing 4930th data
processing 4940th data
processing 4950th data
processing 4960th data
processing 4970th data
processing 4980th data
processing 4990th data
processing 5000th data
processing 5010th data
processing 5020th data
processing 5030th data
processing 5040th data
processing 5050th data
processing 5060th data
processing 5070th data
processing 5080th data
processing 5090th data
processing 5100th data
processing 5110th data
processing 5120th data
processing 5130th data
processing 5140th data
processing 5150th data
processing 5160th data
processing 5170th data
processing 5180th data
processing 5190th data
processing 5200th data
processing 5210th data
processing 5220th data
processing 5230th data
processing 5240th data
processing 5250th data
processing 5260th data
processing 5270th data
processing 5280th data
processing 5290th data
processing 5300th data
processing 5310th data
processing 5320th data
processing 5330th data
processing 5340th data
processing 5350th data
processing 5360th data
processing 5370th data
processing 5380th data
processing 5390th data
processing 5400th data
processing 5410th data
processing 5420th data
processing 5430th data
processing 5440th data
processing 5450th data
processing 5460th data
processing 5470th data
processing 5480th data
processing 5490th data
processing 5500th data
processing 5510th data
processing 5520th data
processing 5530th data
processing 5540th data
processing 5550th data
processing 5560th data
processing 5570th data
processing 5580th data
processing 5590th data
processing 5600th data
processing 5610th data
processing 5620th data
processing 5630th data
processing 5640th data
processing 5650th data
processing 5660th data
processing 5670th data
processing 5680th data
processing 5690th data
processing 5700th data
processing 5710th data
processing 5720th data
processing 5730th data
processing 5740th data
processing 5750th data
processing 5760th data
processing 5770th data
processing 5780th data
processing 5790th data
processing 5800th data
processing 5810th data
processing 5820th data
processing 5830th data
processing 5840th data
processing 5850th data
processing 5860th data
processing 5870th data
processing 5880th data
processing 5890th data
processing 5900th data
processing 5910th data
processing 5920th data
processing 5930th data
processing 5940th data
processing 5950th data
processing 5960th data
processing 5970th data
processing 5980th data
processing 5990th data
processing 6000th data
processing 6010th data
processing 6020th data
processing 6030th data
processing 6040th data
processing 6050th data
processing 6060th data
processing 6070th data
processing 6080th data
processing 6090th data
processing 6100th data
processing 6110th data
processing 6120th data
processing 6130th data
processing 6140th data
processing 6150th data
processing 6160th data
processing 6170th data
processing 6180th data
processing 6190th data
processing 6200th data
processing 6210th data
processing 6220th data
processing 6230th data
processing 6240th data
processing 6250th data
processing 6260th data
processing 6270th data
processing 6280th data
processing 6290th data
processing 6300th data
processing 6310th data
processing 6320th data
processing 6330th data
processing 6340th data
processing 6350th data
processing 6360th data
processing 6370th data
processing 6380th data
processing 6390th data
processing 6400th data
processing 6410th data
processing 6420th data
processing 6430th data
processing 6440th data
processing 6450th data
processing 6460th data
processing 6470th data
processing 6480th data
processing 6490th data
processing 6500th data
processing 6510th data
processing 6520th data
processing 6530th data
processing 6540th data
processing 6550th data
processing 6560th data
processing 6570th data
processing 6580th data
processing 6590th data
processing 6600th data
processing 6610th data
processing 6620th data
processing 6630th data
processing 6640th data
processing 6650th data
processing 6660th data
processing 6670th data
processing 6680th data
processing 6690th data
processing 6700th data
processing 6710th data
processing 6720th data
processing 6730th data
processing 6740th data
processing 6750th data
processing 6760th data
processing 6770th data
processing 6780th data
processing 6790th data
processing 6800th data
processing 6810th data
processing 6820th data
processing 6830th data
processing 6840th data
processing 6850th data
processing 6860th data
processing 6870th data
processing 6880th data
processing 6890th data
processing 6900th data
processing 6910th data
processing 6920th data
processing 6930th data
processing 6940th data
processing 6950th data
processing 6960th data
processing 6970th data
processing 6980th data
processing 6990th data
processing 7000th data
processing 7010th data
processing 7020th data
processing 7030th data
processing 7040th data
processing 7050th data
processing 7060th data
processing 7070th data
processing 7080th data
processing 7090th data
processing 7100th data
processing 7110th data
processing 7120th data
processing 7130th data
processing 7140th data
processing 7150th data
processing 7160th data
processing 7170th data
processing 7180th data
processing 7190th data
processing 7200th data
processing 7210th data
processing 7220th data
processing 7230th data
processing 7240th data
processing 7250th data
processing 7260th data
processing 7270th data
processing 7280th data
processing 7290th data
processing 7300th data
processing 7310th data
processing 7320th data
processing 7330th data
processing 7340th data
processing 7350th data
processing 7360th data
processing 7370th data
processing 7380th data
processing 7390th data
processing 7400th data
processing 7410th data
processing 7420th data
processing 7430th data
processing 7440th data
processing 7450th data
processing 7460th data
processing 7470th data
processing 7480th data
processing 7490th data
processing 7500th data
processing 7510th data
processing 7520th data
processing 7530th data
processing 7540th data
processing 7550th data
processing 7560th data
processing 7570th data
processing 7580th data
processing 7590th data
processing 7600th data
processing 7610th data
processing 7620th data
processing 7630th data
processing 7640th data
processing 7650th data
processing 7660th data
processing 7670th data
processing 7680th data
processing 7690th data
processing 7700th data
processing 7710th data
processing 7720th data
processing 7730th data
processing 7740th data
processing 7750th data
processing 7760th data
processing 7770th data
processing 7780th data
processing 7790th data
processing 7800th data
processing 7810th data
processing 7820th data
processing 7830th data
processing 7840th data
processing 7850th data
processing 7860th data
processing 7870th data
processing 7880th data
processing 7890th data
processing 7900th data
processing 7910th data
processing 7920th data
processing 7930th data
processing 7940th data
processing 7950th data
processing 7960th data
processing 7970th data
processing 7980th data
processing 7990th data
processing 8000th data
processing 8010th data
processing 8020th data
processing 8030th data
processing 8040th data
processing 8050th data
processing 8060th data
processing 8070th data
processing 8080th data
processing 8090th data
processing 8100th data
processing 8110th data
processing 8120th data
processing 8130th data
processing 8140th data
processing 8150th data
processing 8160th data
processing 8170th data
processing 8180th data
processing 8190th data
processing 8200th data
processing 8210th data
processing 8220th data
processing 8230th data
processing 8240th data
processing 8250th data
processing 8260th data
processing 8270th data
processing 8280th data
processing 8290th data
processing 8300th data
processing 8310th data
processing 8320th data
processing 8330th data
processing 8340th data
processing 8350th data
processing 8360th data
processing 8370th data
processing 8380th data
processing 8390th data
processing 8400th data
processing 8410th data
processing 8420th data
processing 8430th data
processing 8440th data
processing 8450th data
processing 8460th data
processing 8470th data
processing 8480th data
processing 8490th data
processing 8500th data
processing 8510th data
processing 8520th data
processing 8530th data
processing 8540th data
processing 8550th data
processing 8560th data
processing 8570th data
processing 8580th data
processing 8590th data
processing 8600th data
processing 8610th data
processing 8620th data
processing 8630th data
processing 8640th data
processing 8650th data
processing 8660th data
processing 8670th data
processing 8680th data
processing 8690th data
processing 8700th data
processing 8710th data
processing 8720th data
processing 8730th data
processing 8740th data
processing 8750th data
processing 8760th data
processing 8770th data
processing 8780th data
processing 8790th data
processing 8800th data
processing 8810th data
processing 8820th data
processing 8830th data
processing 8840th data
processing 8850th data
processing 8860th data
processing 8870th data
processing 8880th data
processing 8890th data
processing 8900th data
processing 8910th data
processing 8920th data
processing 8930th data
processing 8940th data
processing 8950th data
processing 8960th data
processing 8970th data
processing 8980th data
processing 8990th data
processing 9000th data
processing 9010th data
processing 9020th data
processing 9030th data
processing 9040th data
processing 9050th data
processing 9060th data
processing 9070th data
processing 9080th data
processing 9090th data
processing 9100th data
processing 9110th data
processing 9120th data
processing 9130th data
processing 9140th data
processing 9150th data
processing 9160th data
processing 9170th data
processing 9180th data
processing 9190th data
processing 9200th data
processing 9210th data
processing 9220th data
processing 9230th data
processing 9240th data
processing 9250th data
processing 9260th data
processing 9270th data
processing 9280th data
processing 9290th data
processing 9300th data
processing 9310th data
processing 9320th data
processing 9330th data
processing 9340th data
processing 9350th data
processing 9360th data
processing 9370th data
processing 9380th data
processing 9390th data
processing 9400th data
processing 9410th data
processing 9420th data
processing 9430th data
processing 9440th data
processing 9450th data
processing 9460th data
processing 9470th data
processing 9480th data
processing 9490th data
processing 9500th data
processing 9510th data
processing 9520th data
processing 9530th data
processing 9540th data
processing 9550th data
processing 9560th data
processing 9570th data
processing 9580th data
processing 9590th data
processing 9600th data
processing 9610th data
processing 9620th data
processing 9630th data
processing 9640th data
processing 9650th data
processing 9660th data
processing 9670th data
processing 9680th data
processing 9690th data
processing 9700th data
processing 9710th data
processing 9720th data
processing 9730th data
processing 9740th data
processing 9750th data
processing 9760th data
processing 9770th data
processing 9780th data
processing 9790th data
processing 9800th data
processing 9810th data
processing 9820th data
processing 9830th data
processing 9840th data
processing 9850th data
processing 9860th data
processing 9870th data
processing 9880th data
processing 9890th data
processing 9900th data
processing 9910th data
processing 9920th data
processing 9930th data
processing 9940th data
processing 9950th data
processing 9960th data
processing 9970th data
processing 9980th data
processing 9990th data
processing 10000th data
FMOE: [Rank 1] Average Elapsed Time: 54.20384738273621ms 

FMOE: [Rank 3] Average Elapsed Time: 54.209370526123045ms 

FMOE: [Rank 2] Average Elapsed Time: 54.208232440948485ms 

FMOE: [Rank 0] Average Elapsed Time: 54.20862258491516ms 

pmoe vs. fmoe 1.0082695484161377
pmoe vs. fmoe value tensor([1.1956, 0.8994, 1.0259,  ..., 0.9835, 1.0264, 0.9930])
pmoe time 54.66967010498047
gpuidx: 2 with rank: 2 with world size: 4
gpuidx: 3 with rank: 3 with world size: 4
gpuidx: 0 with rank: 0 with world size: 4
initialized the distributed DNN
gpuidx: 1 with rank: 1 with world size: 4
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:11<00:11, 11.58s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:11<00:11, 11.30s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:11<00:11, 11.54s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:11<00:11, 11.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:15<00:00,  7.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:15<00:00,  7.69s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:15<00:00,  7.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:15<00:00,  7.88s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:15<00:00,  7.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:15<00:00,  7.82s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:15<00:00,  7.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:15<00:00,  7.73s/it]
WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:164: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate = torch.load(f"{weight_path}/layer_{i}_gate.pt").to(gpu_idx)

W0113 19:33:08.992777 2292889 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:164: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate = torch.load(f"{weight_path}/layer_{i}_gate.pt").to(gpu_idx)

Wrapping layer 0 / 22 from mlp to fMoE
WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:164: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate = torch.load(f"{weight_path}/layer_{i}_gate.pt").to(gpu_idx)

W0113 19:33:10.188221 2292888 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:164: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate = torch.load(f"{weight_path}/layer_{i}_gate.pt").to(gpu_idx)

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:164: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate = torch.load(f"{weight_path}/layer_{i}_gate.pt").to(gpu_idx)

W0113 19:33:10.207808 2292886 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:164: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate = torch.load(f"{weight_path}/layer_{i}_gate.pt").to(gpu_idx)

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:164: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate = torch.load(f"{weight_path}/layer_{i}_gate.pt").to(gpu_idx)

W0113 19:33:10.214995 2292887 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:164: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate = torch.load(f"{weight_path}/layer_{i}_gate.pt").to(gpu_idx)

Wrapping layer 1 / 22 from mlp to fMoE
Wrapping layer 2 / 22 from mlp to fMoE
Wrapping layer 3 / 22 from mlp to fMoE
Wrapping layer 4 / 22 from mlp to fMoE
Wrapping layer 5 / 22 from mlp to fMoE
Wrapping layer 6 / 22 from mlp to fMoE
Wrapping layer 7 / 22 from mlp to fMoE
Wrapping layer 8 / 22 from mlp to fMoE
Wrapping layer 9 / 22 from mlp to fMoE
Wrapping layer 10 / 22 from mlp to fMoE
Wrapping layer 11 / 22 from mlp to fMoE
Wrapping layer 12 / 22 from mlp to fMoE
Wrapping layer 13 / 22 from mlp to fMoE
Wrapping layer 14 / 22 from mlp to fMoE
Wrapping layer 15 / 22 from mlp to fMoE
Wrapping layer 16 / 22 from mlp to fMoE
Wrapping layer 17 / 22 from mlp to fMoE
Wrapping layer 18 / 22 from mlp to fMoE
Wrapping layer 19 / 22 from mlp to fMoE
Wrapping layer 20 / 22 from mlp to fMoE
Wrapping layer 21 / 22 from mlp to fMoE
processing 0th data
processing 10th data
processing 20th data
processing 30th data
processing 40th data
processing 50th data
processing 60th data
processing 70th data
processing 80th data
processing 90th data
processing 100th data
processing 110th data
processing 120th data
processing 130th data
processing 140th data
processing 150th data
processing 160th data
processing 170th data
processing 180th data
processing 190th data
processing 200th data
processing 210th data
processing 220th data
processing 230th data
processing 240th data
processing 250th data
processing 260th data
processing 270th data
processing 280th data
processing 290th data
processing 300th data
processing 310th data
processing 320th data
processing 330th data
processing 340th data
processing 350th data
processing 360th data
processing 370th data
processing 380th data
processing 390th data
processing 400th data
processing 410th data
processing 420th data
processing 430th data
processing 440th data
processing 450th data
processing 460th data
processing 470th data
processing 480th data
processing 490th data
processing 500th data
processing 510th data
processing 520th data
processing 530th data
processing 540th data
processing 550th data
processing 560th data
processing 570th data
processing 580th data
processing 590th data
processing 600th data
processing 610th data
processing 620th data
processing 630th data
processing 640th data
processing 650th data
processing 660th data
processing 670th data
processing 680th data
processing 690th data
processing 700th data
processing 710th data
processing 720th data
processing 730th data
processing 740th data
processing 750th data
processing 760th data
processing 770th data
processing 780th data
processing 790th data
processing 800th data
processing 810th data
processing 820th data
processing 830th data
processing 840th data
processing 850th data
processing 860th data
processing 870th data
processing 880th data
processing 890th data
processing 900th data
processing 910th data
processing 920th data
processing 930th data
processing 940th data
processing 950th data
processing 960th data
processing 970th data
processing 980th data
processing 990th data
processing 1000th data
processing 1010th data
processing 1020th data
processing 1030th data
processing 1040th data
processing 1050th data
processing 1060th data
processing 1070th data
processing 1080th data
processing 1090th data
processing 1100th data
processing 1110th data
processing 1120th data
processing 1130th data
processing 1140th data
processing 1150th data
processing 1160th data
processing 1170th data
processing 1180th data
processing 1190th data
processing 1200th data
processing 1210th data
processing 1220th data
processing 1230th data
processing 1240th data
processing 1250th data
processing 1260th data
processing 1270th data
processing 1280th data
processing 1290th data
processing 1300th data
processing 1310th data
processing 1320th data
processing 1330th data
processing 1340th data
processing 1350th data
processing 1360th data
processing 1370th data
processing 1380th data
processing 1390th data
processing 1400th data
processing 1410th data
processing 1420th data
processing 1430th data
processing 1440th data
processing 1450th data
processing 1460th data
processing 1470th data
processing 1480th data
processing 1490th data
processing 1500th data
processing 1510th data
processing 1520th data
processing 1530th data
processing 1540th data
processing 1550th data
processing 1560th data
processing 1570th data
processing 1580th data
processing 1590th data
processing 1600th data
processing 1610th data
processing 1620th data
processing 1630th data
processing 1640th data
processing 1650th data
processing 1660th data
processing 1670th data
processing 1680th data
processing 1690th data
processing 1700th data
processing 1710th data
processing 1720th data
processing 1730th data
processing 1740th data
processing 1750th data
processing 1760th data
processing 1770th data
processing 1780th data
processing 1790th data
processing 1800th data
processing 1810th data
processing 1820th data
processing 1830th data
processing 1840th data
processing 1850th data
processing 1860th data
processing 1870th data
processing 1880th data
processing 1890th data
processing 1900th data
processing 1910th data
processing 1920th data
processing 1930th data
processing 1940th data
processing 1950th data
processing 1960th data
processing 1970th data
processing 1980th data
processing 1990th data
processing 2000th data
processing 2010th data
processing 2020th data
processing 2030th data
processing 2040th data
processing 2050th data
processing 2060th data
processing 2070th data
processing 2080th data
processing 2090th data
processing 2100th data
processing 2110th data
processing 2120th data
processing 2130th data
processing 2140th data
processing 2150th data
processing 2160th data
processing 2170th data
processing 2180th data
processing 2190th data
processing 2200th data
processing 2210th data
processing 2220th data
processing 2230th data
processing 2240th data
processing 2250th data
processing 2260th data
processing 2270th data
processing 2280th data
processing 2290th data
processing 2300th data
processing 2310th data
processing 2320th data
processing 2330th data
processing 2340th data
processing 2350th data
processing 2360th data
processing 2370th data
processing 2380th data
processing 2390th data
processing 2400th data
processing 2410th data
processing 2420th data
processing 2430th data
processing 2440th data
processing 2450th data
processing 2460th data
processing 2470th data
processing 2480th data
processing 2490th data
processing 2500th data
processing 2510th data
processing 2520th data
processing 2530th data
processing 2540th data
processing 2550th data
processing 2560th data
processing 2570th data
processing 2580th data
processing 2590th data
processing 2600th data
processing 2610th data
processing 2620th data
processing 2630th data
processing 2640th data
processing 2650th data
processing 2660th data
processing 2670th data
processing 2680th data
processing 2690th data
processing 2700th data
processing 2710th data
processing 2720th data
processing 2730th data
processing 2740th data
processing 2750th data
processing 2760th data
processing 2770th data
processing 2780th data
processing 2790th data
processing 2800th data
processing 2810th data
processing 2820th data
processing 2830th data
processing 2840th data
processing 2850th data
processing 2860th data
processing 2870th data
processing 2880th data
processing 2890th data
processing 2900th data
processing 2910th data
processing 2920th data
processing 2930th data
processing 2940th data
processing 2950th data
processing 2960th data
processing 2970th data
processing 2980th data
processing 2990th data
processing 3000th data
processing 3010th data
processing 3020th data
processing 3030th data
processing 3040th data
processing 3050th data
processing 3060th data
processing 3070th data
processing 3080th data
processing 3090th data
processing 3100th data
processing 3110th data
processing 3120th data
processing 3130th data
processing 3140th data
processing 3150th data
processing 3160th data
processing 3170th data
processing 3180th data
processing 3190th data
processing 3200th data
processing 3210th data
processing 3220th data
processing 3230th data
processing 3240th data
processing 3250th data
processing 3260th data
processing 3270th data
processing 3280th data
processing 3290th data
processing 3300th data
processing 3310th data
processing 3320th data
processing 3330th data
processing 3340th data
processing 3350th data
processing 3360th data
processing 3370th data
processing 3380th data
processing 3390th data
processing 3400th data
processing 3410th data
processing 3420th data
processing 3430th data
processing 3440th data
processing 3450th data
processing 3460th data
processing 3470th data
processing 3480th data
processing 3490th data
processing 3500th data
processing 3510th data
processing 3520th data
processing 3530th data
processing 3540th data
processing 3550th data
processing 3560th data
processing 3570th data
processing 3580th data
processing 3590th data
processing 3600th data
processing 3610th data
processing 3620th data
processing 3630th data
processing 3640th data
processing 3650th data
processing 3660th data
processing 3670th data
processing 3680th data
processing 3690th data
processing 3700th data
processing 3710th data
processing 3720th data
processing 3730th data
processing 3740th data
processing 3750th data
processing 3760th data
processing 3770th data
processing 3780th data
processing 3790th data
processing 3800th data
processing 3810th data
processing 3820th data
processing 3830th data
processing 3840th data
processing 3850th data
processing 3860th data
processing 3870th data
processing 3880th data
processing 3890th data
processing 3900th data
processing 3910th data
processing 3920th data
processing 3930th data
processing 3940th data
processing 3950th data
processing 3960th data
processing 3970th data
processing 3980th data
processing 3990th data
processing 4000th data
processing 4010th data
processing 4020th data
processing 4030th data
processing 4040th data
processing 4050th data
processing 4060th data
processing 4070th data
processing 4080th data
processing 4090th data
processing 4100th data
processing 4110th data
processing 4120th data
processing 4130th data
processing 4140th data
processing 4150th data
processing 4160th data
processing 4170th data
processing 4180th data
processing 4190th data
processing 4200th data
processing 4210th data
processing 4220th data
processing 4230th data
processing 4240th data
processing 4250th data
processing 4260th data
processing 4270th data
processing 4280th data
processing 4290th data
processing 4300th data
processing 4310th data
processing 4320th data
processing 4330th data
processing 4340th data
processing 4350th data
processing 4360th data
processing 4370th data
processing 4380th data
processing 4390th data
processing 4400th data
processing 4410th data
processing 4420th data
processing 4430th data
processing 4440th data
processing 4450th data
processing 4460th data
processing 4470th data
processing 4480th data
processing 4490th data
processing 4500th data
processing 4510th data
processing 4520th data
processing 4530th data
processing 4540th data
processing 4550th data
processing 4560th data
processing 4570th data
processing 4580th data
processing 4590th data
processing 4600th data
processing 4610th data
processing 4620th data
processing 4630th data
processing 4640th data
processing 4650th data
processing 4660th data
processing 4670th data
processing 4680th data
processing 4690th data
processing 4700th data
processing 4710th data
processing 4720th data
processing 4730th data
processing 4740th data
processing 4750th data
processing 4760th data
processing 4770th data
processing 4780th data
processing 4790th data
processing 4800th data
processing 4810th data
processing 4820th data
processing 4830th data
processing 4840th data
processing 4850th data
processing 4860th data
processing 4870th data
processing 4880th data
processing 4890th data
processing 4900th data
processing 4910th data
processing 4920th data
processing 4930th data
processing 4940th data
processing 4950th data
processing 4960th data
processing 4970th data
processing 4980th data
processing 4990th data
processing 5000th data
processing 5010th data
processing 5020th data
processing 5030th data
processing 5040th data
processing 5050th data
processing 5060th data
processing 5070th data
processing 5080th data
processing 5090th data
processing 5100th data
processing 5110th data
processing 5120th data
processing 5130th data
processing 5140th data
processing 5150th data
processing 5160th data
processing 5170th data
processing 5180th data
processing 5190th data
processing 5200th data
processing 5210th data
processing 5220th data
processing 5230th data
processing 5240th data
processing 5250th data
processing 5260th data
processing 5270th data
processing 5280th data
processing 5290th data
processing 5300th data
processing 5310th data
processing 5320th data
processing 5330th data
processing 5340th data
processing 5350th data
processing 5360th data
processing 5370th data
processing 5380th data
processing 5390th data
processing 5400th data
processing 5410th data
processing 5420th data
processing 5430th data
processing 5440th data
processing 5450th data
processing 5460th data
processing 5470th data
processing 5480th data
processing 5490th data
processing 5500th data
processing 5510th data
processing 5520th data
processing 5530th data
processing 5540th data
processing 5550th data
processing 5560th data
processing 5570th data
processing 5580th data
processing 5590th data
processing 5600th data
processing 5610th data
processing 5620th data
processing 5630th data
processing 5640th data
processing 5650th data
processing 5660th data
processing 5670th data
processing 5680th data
processing 5690th data
processing 5700th data
processing 5710th data
processing 5720th data
processing 5730th data
processing 5740th data
processing 5750th data
processing 5760th data
processing 5770th data
processing 5780th data
processing 5790th data
processing 5800th data
processing 5810th data
processing 5820th data
processing 5830th data
processing 5840th data
processing 5850th data
processing 5860th data
processing 5870th data
processing 5880th data
processing 5890th data
processing 5900th data
processing 5910th data
processing 5920th data
processing 5930th data
processing 5940th data
processing 5950th data
processing 5960th data
processing 5970th data
processing 5980th data
processing 5990th data
processing 6000th data
processing 6010th data
processing 6020th data
processing 6030th data
processing 6040th data
processing 6050th data
processing 6060th data
processing 6070th data
processing 6080th data
processing 6090th data
processing 6100th data
processing 6110th data
processing 6120th data
processing 6130th data
processing 6140th data
processing 6150th data
processing 6160th data
processing 6170th data
processing 6180th data
processing 6190th data
processing 6200th data
processing 6210th data
processing 6220th data
processing 6230th data
processing 6240th data
processing 6250th data
processing 6260th data
processing 6270th data
processing 6280th data
processing 6290th data
processing 6300th data
processing 6310th data
processing 6320th data
processing 6330th data
processing 6340th data
processing 6350th data
processing 6360th data
processing 6370th data
processing 6380th data
processing 6390th data
processing 6400th data
processing 6410th data
processing 6420th data
processing 6430th data
processing 6440th data
processing 6450th data
processing 6460th data
processing 6470th data
processing 6480th data
processing 6490th data
processing 6500th data
processing 6510th data
processing 6520th data
processing 6530th data
processing 6540th data
processing 6550th data
processing 6560th data
processing 6570th data
processing 6580th data
processing 6590th data
processing 6600th data
processing 6610th data
processing 6620th data
processing 6630th data
processing 6640th data
processing 6650th data
processing 6660th data
processing 6670th data
processing 6680th data
processing 6690th data
processing 6700th data
processing 6710th data
processing 6720th data
processing 6730th data
processing 6740th data
processing 6750th data
processing 6760th data
processing 6770th data
processing 6780th data
processing 6790th data
processing 6800th data
processing 6810th data
processing 6820th data
processing 6830th data
processing 6840th data
processing 6850th data
processing 6860th data
processing 6870th data
processing 6880th data
processing 6890th data
processing 6900th data
processing 6910th data
processing 6920th data
processing 6930th data
processing 6940th data
processing 6950th data
processing 6960th data
processing 6970th data
processing 6980th data
processing 6990th data
processing 7000th data
processing 7010th data
processing 7020th data
processing 7030th data
processing 7040th data
processing 7050th data
processing 7060th data
processing 7070th data
processing 7080th data
processing 7090th data
processing 7100th data
processing 7110th data
processing 7120th data
processing 7130th data
processing 7140th data
processing 7150th data
processing 7160th data
processing 7170th data
processing 7180th data
processing 7190th data
processing 7200th data
processing 7210th data
processing 7220th data
processing 7230th data
processing 7240th data
processing 7250th data
processing 7260th data
processing 7270th data
processing 7280th data
processing 7290th data
processing 7300th data
processing 7310th data
processing 7320th data
processing 7330th data
processing 7340th data
processing 7350th data
processing 7360th data
processing 7370th data
processing 7380th data
processing 7390th data
processing 7400th data
processing 7410th data
processing 7420th data
processing 7430th data
processing 7440th data
processing 7450th data
processing 7460th data
processing 7470th data
processing 7480th data
processing 7490th data
processing 7500th data
processing 7510th data
processing 7520th data
processing 7530th data
processing 7540th data
processing 7550th data
processing 7560th data
processing 7570th data
processing 7580th data
processing 7590th data
processing 7600th data
processing 7610th data
processing 7620th data
processing 7630th data
processing 7640th data
processing 7650th data
processing 7660th data
processing 7670th data
processing 7680th data
processing 7690th data
processing 7700th data
processing 7710th data
processing 7720th data
processing 7730th data
processing 7740th data
processing 7750th data
processing 7760th data
processing 7770th data
processing 7780th data
processing 7790th data
processing 7800th data
processing 7810th data
processing 7820th data
processing 7830th data
processing 7840th data
processing 7850th data
processing 7860th data
processing 7870th data
processing 7880th data
processing 7890th data
processing 7900th data
processing 7910th data
processing 7920th data
processing 7930th data
processing 7940th data
processing 7950th data
processing 7960th data
processing 7970th data
processing 7980th data
processing 7990th data
processing 8000th data
processing 8010th data
processing 8020th data
processing 8030th data
processing 8040th data
processing 8050th data
processing 8060th data
processing 8070th data
processing 8080th data
processing 8090th data
processing 8100th data
processing 8110th data
processing 8120th data
processing 8130th data
processing 8140th data
processing 8150th data
processing 8160th data
processing 8170th data
processing 8180th data
processing 8190th data
processing 8200th data
processing 8210th data
processing 8220th data
processing 8230th data
processing 8240th data
processing 8250th data
processing 8260th data
processing 8270th data
processing 8280th data
processing 8290th data
processing 8300th data
processing 8310th data
processing 8320th data
processing 8330th data
processing 8340th data
processing 8350th data
processing 8360th data
processing 8370th data
processing 8380th data
processing 8390th data
processing 8400th data
processing 8410th data
processing 8420th data
processing 8430th data
processing 8440th data
processing 8450th data
processing 8460th data
processing 8470th data
processing 8480th data
processing 8490th data
processing 8500th data
processing 8510th data
processing 8520th data
processing 8530th data
processing 8540th data
processing 8550th data
processing 8560th data
processing 8570th data
processing 8580th data
processing 8590th data
processing 8600th data
processing 8610th data
processing 8620th data
processing 8630th data
processing 8640th data
processing 8650th data
processing 8660th data
processing 8670th data
processing 8680th data
processing 8690th data
processing 8700th data
processing 8710th data
processing 8720th data
processing 8730th data
processing 8740th data
processing 8750th data
processing 8760th data
processing 8770th data
processing 8780th data
processing 8790th data
processing 8800th data
processing 8810th data
processing 8820th data
processing 8830th data
processing 8840th data
processing 8850th data
processing 8860th data
processing 8870th data
processing 8880th data
processing 8890th data
processing 8900th data
processing 8910th data
processing 8920th data
processing 8930th data
processing 8940th data
processing 8950th data
processing 8960th data
processing 8970th data
processing 8980th data
processing 8990th data
processing 9000th data
processing 9010th data
processing 9020th data
processing 9030th data
processing 9040th data
processing 9050th data
processing 9060th data
processing 9070th data
processing 9080th data
processing 9090th data
processing 9100th data
processing 9110th data
processing 9120th data
processing 9130th data
processing 9140th data
processing 9150th data
processing 9160th data
processing 9170th data
processing 9180th data
processing 9190th data
processing 9200th data
processing 9210th data
processing 9220th data
processing 9230th data
processing 9240th data
processing 9250th data
processing 9260th data
processing 9270th data
processing 9280th data
processing 9290th data
processing 9300th data
processing 9310th data
processing 9320th data
processing 9330th data
processing 9340th data
processing 9350th data
processing 9360th data
processing 9370th data
processing 9380th data
processing 9390th data
processing 9400th data
processing 9410th data
processing 9420th data
processing 9430th data
processing 9440th data
processing 9450th data
processing 9460th data
processing 9470th data
processing 9480th data
processing 9490th data
processing 9500th data
processing 9510th data
processing 9520th data
processing 9530th data
processing 9540th data
processing 9550th data
processing 9560th data
processing 9570th data
processing 9580th data
processing 9590th data
processing 9600th data
processing 9610th data
processing 9620th data
processing 9630th data
processing 9640th data
processing 9650th data
processing 9660th data
processing 9670th data
processing 9680th data
processing 9690th data
processing 9700th data
processing 9710th data
processing 9720th data
processing 9730th data
processing 9740th data
processing 9750th data
processing 9760th data
processing 9770th data
processing 9780th data
processing 9790th data
processing 9800th data
processing 9810th data
processing 9820th data
processing 9830th data
processing 9840th data
processing 9850th data
processing 9860th data
processing 9870th data
processing 9880th data
processing 9890th data
processing 9900th data
processing 9910th data
processing 9920th data
processing 9930th data
processing 9940th data
processing 9950th data
processing 9960th data
processing 9970th data
processing 9980th data
processing 9990th data
processing 10000th data
FMOE: [Rank 2] Average Elapsed Time: 515.0783344177246ms 

FMOE: [Rank 1] Average Elapsed Time: 512.9720002738952ms 

FMOE: [Rank 3] Average Elapsed Time: 515.6878148597717ms 

FMOE: [Rank 0] Average Elapsed Time: 514.724147592163ms 

gpuidx: 0 with rank: 0 with world size: 2
initialized the distributed DNN
gpuidx: 1 with rank: 1 with world size: 2
The repository for deepseek-ai/deepseek-moe-16b-base contains custom code which must be executed to correctly load the model. You can inspect the repository content at https://hf.co/deepseek-ai/deepseek-moe-16b-base.
You can avoid this prompt in future by passing the argument `trust_remote_code=True`.

Do you wish to run the custom code? [y/N] The repository for deepseek-ai/deepseek-moe-16b-base contains custom code which must be executed to correctly load the model. You can inspect the repository content at https://hf.co/deepseek-ai/deepseek-moe-16b-base.
You can avoid this prompt in future by passing the argument `trust_remote_code=True`.

Do you wish to run the custom code? [y/N] [rank0]: Traceback (most recent call last):
[rank0]:   File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/transformers/dynamic_module_utils.py", line 652, in resolve_trust_remote_code
[rank0]:     answer = input(
[rank0]:              ^^^^^^
[rank0]:   File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/transformers/dynamic_module_utils.py", line 633, in _raise_timeout_error
[rank0]:     raise ValueError(
[rank0]: ValueError: Loading this model requires you to execute custom code contained in the model repository on your local machine. Please set the option `trust_remote_code=True` to permit loading of this model.

[rank0]: During handling of the above exception, another exception occurred:

[rank0]: Traceback (most recent call last):
[rank0]:   File "/data/home/wjbang/workspace/pMoE/pMoE/main.py", line 409, in <module>
[rank0]:     fmoe_time = baseline(args, mesh_shape=mesh_shape, mesh_dims=mesh_dims, dataloader=dataloader, iteration=10000)
[rank0]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/data/home/wjbang/workspace/pMoE/pMoE/main.py", line 368, in baseline
[rank0]:     raise e
[rank0]:   File "/data/home/wjbang/workspace/pMoE/pMoE/main.py", line 283, in baseline
[rank0]:     model = load_deepseek(gpu_idx)
[rank0]:             ^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank0]:     return func(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py", line 265, in load_deepseek
[rank0]:     model = AutoModelForCausalLM.from_pretrained(model_name, device_map=None, torch_dtype=torch.bfloat16).to(gpu_idx)
[rank0]:             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py", line 526, in from_pretrained
[rank0]:     config, kwargs = AutoConfig.from_pretrained(
[rank0]:                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/transformers/models/auto/configuration_auto.py", line 1024, in from_pretrained
[rank0]:     trust_remote_code = resolve_trust_remote_code(
[rank0]:                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/transformers/dynamic_module_utils.py", line 665, in resolve_trust_remote_code
[rank0]:     raise ValueError(
[rank0]: ValueError: The repository for deepseek-ai/deepseek-moe-16b-base contains custom code which must be executed to correctly load the model. You can inspect the repository content at https://hf.co/deepseek-ai/deepseek-moe-16b-base.
[rank0]: Please pass the argument `trust_remote_code=True` to allow custom code to be run.
[rank1]: Traceback (most recent call last):
[rank1]:   File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/transformers/dynamic_module_utils.py", line 652, in resolve_trust_remote_code
[rank1]:     answer = input(
[rank1]:              ^^^^^^
[rank1]:   File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/transformers/dynamic_module_utils.py", line 633, in _raise_timeout_error
[rank1]:     raise ValueError(
[rank1]: ValueError: Loading this model requires you to execute custom code contained in the model repository on your local machine. Please set the option `trust_remote_code=True` to permit loading of this model.

[rank1]: During handling of the above exception, another exception occurred:

[rank1]: Traceback (most recent call last):
[rank1]:   File "/data/home/wjbang/workspace/pMoE/pMoE/main.py", line 409, in <module>
[rank1]:     fmoe_time = baseline(args, mesh_shape=mesh_shape, mesh_dims=mesh_dims, dataloader=dataloader, iteration=10000)
[rank1]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/data/home/wjbang/workspace/pMoE/pMoE/main.py", line 368, in baseline
[rank1]:     raise e
[rank1]:   File "/data/home/wjbang/workspace/pMoE/pMoE/main.py", line 283, in baseline
[rank1]:     model = load_deepseek(gpu_idx)
[rank1]:             ^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank1]:     return func(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py", line 265, in load_deepseek
[rank1]:     model = AutoModelForCausalLM.from_pretrained(model_name, device_map=None, torch_dtype=torch.bfloat16).to(gpu_idx)
[rank1]:             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py", line 526, in from_pretrained
[rank1]:     config, kwargs = AutoConfig.from_pretrained(
[rank1]:                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/transformers/models/auto/configuration_auto.py", line 1024, in from_pretrained
[rank1]:     trust_remote_code = resolve_trust_remote_code(
[rank1]:                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/transformers/dynamic_module_utils.py", line 665, in resolve_trust_remote_code
[rank1]:     raise ValueError(
[rank1]: ValueError: The repository for deepseek-ai/deepseek-moe-16b-base contains custom code which must be executed to correctly load the model. You can inspect the repository content at https://hf.co/deepseek-ai/deepseek-moe-16b-base.
[rank1]: Please pass the argument `trust_remote_code=True` to allow custom code to be run.
W0115 19:28:44.468000 140621927417664 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 3471273 closing signal SIGTERM
E0115 19:28:45.090000 140621927417664 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 0 (pid: 3471272) of binary: /home/wjbang/anaconda3/envs/shan_cuda12.1/bin/python
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/distributed/run.py", line 905, in <module>
    main()
  File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 348, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/distributed/run.py", line 901, in main
    run(args)
  File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-01-15_19:28:44
  host      : gpu-1.novalocal
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 3471272)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
gpuidx: 0 with rank: 0 with world size: 2
initialized the distributed DNN
gpuidx: 1 with rank: 1 with world size: 2
A new version of the following files was downloaded from https://huggingface.co/deepseek-ai/deepseek-moe-16b-base:
- configuration_deepseek.py
. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.
A new version of the following files was downloaded from https://huggingface.co/deepseek-ai/deepseek-moe-16b-base:
- configuration_deepseek.py
. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.
A new version of the following files was downloaded from https://huggingface.co/deepseek-ai/deepseek-moe-16b-base:
- modeling_deepseek.py
. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.
A new version of the following files was downloaded from https://huggingface.co/deepseek-ai/deepseek-moe-16b-base:
- modeling_deepseek.py
. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.
Downloading shards:   0%|          | 0/7 [00:00<?, ?it/s]Downloading shards:   0%|          | 0/7 [00:00<?, ?it/s]Downloading shards:  14%|█▍        | 1/7 [02:49<16:54, 169.15s/it]Downloading shards:  14%|█▍        | 1/7 [02:49<16:54, 169.16s/it]Downloading shards:  29%|██▊       | 2/7 [05:37<14:03, 168.75s/it]Downloading shards:  29%|██▊       | 2/7 [05:37<14:03, 168.78s/it]Downloading shards:  43%|████▎     | 3/7 [08:28<11:18, 169.50s/it]Downloading shards:  43%|████▎     | 3/7 [08:28<11:18, 169.51s/it]Downloading shards:  57%|█████▋    | 4/7 [10:28<07:30, 150.08s/it]Downloading shards:  57%|█████▋    | 4/7 [10:28<07:30, 150.11s/it]Downloading shards:  71%|███████▏  | 5/7 [12:28<04:38, 139.32s/it]Downloading shards:  71%|███████▏  | 5/7 [12:28<04:38, 139.34s/it]Downloading shards:  86%|████████▌ | 6/7 [14:28<02:12, 132.89s/it]Downloading shards:  86%|████████▌ | 6/7 [14:29<02:12, 132.91s/it]Downloading shards: 100%|██████████| 7/7 [15:35<00:00, 111.15s/it]Downloading shards: 100%|██████████| 7/7 [15:35<00:00, 133.63s/it]
Downloading shards: 100%|██████████| 7/7 [15:35<00:00, 111.16s/it]Downloading shards: 100%|██████████| 7/7 [15:35<00:00, 133.64s/it]
Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:11<01:07, 11.27s/it]Loading checkpoint shards:  14%|█▍        | 1/7 [00:11<01:08, 11.38s/it]Loading checkpoint shards:  29%|██▊       | 2/7 [00:17<00:42,  8.52s/it]Loading checkpoint shards:  29%|██▊       | 2/7 [00:18<00:43,  8.61s/it]Loading checkpoint shards:  43%|████▎     | 3/7 [00:22<00:26,  6.63s/it]Loading checkpoint shards:  43%|████▎     | 3/7 [00:22<00:26,  6.71s/it]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:26<00:16,  5.64s/it]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:26<00:16,  5.63s/it]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:30<00:10,  5.21s/it]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:30<00:10,  5.20s/it]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:34<00:04,  4.76s/it]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:34<00:04,  4.77s/it]Loading checkpoint shards: 100%|██████████| 7/7 [00:36<00:00,  3.77s/it]Loading checkpoint shards: 100%|██████████| 7/7 [00:36<00:00,  5.22s/it]
Loading checkpoint shards: 100%|██████████| 7/7 [00:36<00:00,  3.79s/it]Loading checkpoint shards: 100%|██████████| 7/7 [00:36<00:00,  5.21s/it]
Wrapping layer 1 / 28 from mlp to fMoE
[rank0]: Traceback (most recent call last):
[rank0]:   File "/data/home/wjbang/workspace/pMoE/pMoE/main.py", line 409, in <module>
[rank0]:     fmoe_time = baseline(args, mesh_shape=mesh_shape, mesh_dims=mesh_dims, dataloader=dataloader, iteration=10000)
[rank0]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/data/home/wjbang/workspace/pMoE/pMoE/main.py", line 368, in baseline
[rank0]:     raise e
[rank0]:   File "/data/home/wjbang/workspace/pMoE/pMoE/main.py", line 284, in baseline
[rank0]:     model = deepseek_wrapper(model, "fMoE", {"total_experts": num_experts, "d_model": 2048, "d_hidden": 1408, "top_k": 2, "world_size": world_size, "moe_group": group}, ctx, gpu_rank, gpu_idx).to(gpu_idx)
[rank0]:             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank0]:     return func(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py", line 214, in deepseek_wrapper
[rank0]:     model.model.layers[i].mlp = FMoETransformerMLP(num_expert=total_experts, d_model=d_model, d_hidden=d_hidden, top_k=top_k, world_size=world_size, moe_group=moe_group, is_deepseek=True).to(torch.bfloat16)
[rank0]:                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/fastmoe-1.1.0-py3.12-linux-x86_64.egg/fmoe/transformer.py", line 111, in __init__
[rank0]:     self.shared_experts = Custom_DeepseekMLP(d_model, 2 * d_hidden) # config.n_shared_experts = 2
[rank0]:     ^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1757, in __setattr__
[rank0]:     raise AttributeError(
[rank0]: AttributeError: cannot assign module before Module.__init__() call
[rank1]: Traceback (most recent call last):
[rank1]:   File "/data/home/wjbang/workspace/pMoE/pMoE/main.py", line 409, in <module>
[rank1]:     fmoe_time = baseline(args, mesh_shape=mesh_shape, mesh_dims=mesh_dims, dataloader=dataloader, iteration=10000)
[rank1]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/data/home/wjbang/workspace/pMoE/pMoE/main.py", line 368, in baseline
[rank1]:     raise e
[rank1]:   File "/data/home/wjbang/workspace/pMoE/pMoE/main.py", line 284, in baseline
[rank1]:     model = deepseek_wrapper(model, "fMoE", {"total_experts": num_experts, "d_model": 2048, "d_hidden": 1408, "top_k": 2, "world_size": world_size, "moe_group": group}, ctx, gpu_rank, gpu_idx).to(gpu_idx)
[rank1]:             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank1]:     return func(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py", line 214, in deepseek_wrapper
[rank1]:     model.model.layers[i].mlp = FMoETransformerMLP(num_expert=total_experts, d_model=d_model, d_hidden=d_hidden, top_k=top_k, world_size=world_size, moe_group=moe_group, is_deepseek=True).to(torch.bfloat16)
[rank1]:                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/fastmoe-1.1.0-py3.12-linux-x86_64.egg/fmoe/transformer.py", line 111, in __init__
[rank1]:     self.shared_experts = Custom_DeepseekMLP(d_model, 2 * d_hidden) # config.n_shared_experts = 2
[rank1]:     ^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1757, in __setattr__
[rank1]:     raise AttributeError(
[rank1]: AttributeError: cannot assign module before Module.__init__() call
W0115 19:52:41.593000 140464715802432 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 3472924 closing signal SIGTERM
E0115 19:52:41.758000 140464715802432 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 0 (pid: 3472923) of binary: /home/wjbang/anaconda3/envs/shan_cuda12.1/bin/python
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/distributed/run.py", line 905, in <module>
    main()
  File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 348, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/distributed/run.py", line 901, in main
    run(args)
  File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-01-15_19:52:41
  host      : gpu-1.novalocal
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 3472923)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
gpuidx: 1 with rank: 1 with world size: 2
gpuidx: 0 with rank: 0 with world size: 2
initialized the distributed DNN
Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:08<00:49,  8.29s/it]Loading checkpoint shards:  14%|█▍        | 1/7 [00:07<00:47,  7.87s/it]Loading checkpoint shards:  29%|██▊       | 2/7 [00:09<00:21,  4.21s/it]Loading checkpoint shards:  29%|██▊       | 2/7 [00:09<00:20,  4.06s/it]Loading checkpoint shards:  43%|████▎     | 3/7 [00:10<00:11,  2.90s/it]Loading checkpoint shards:  43%|████▎     | 3/7 [00:10<00:11,  2.81s/it]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:12<00:06,  2.29s/it]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:11<00:06,  2.23s/it]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:13<00:03,  1.94s/it]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:13<00:03,  1.91s/it]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:15<00:01,  1.74s/it]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:14<00:01,  1.71s/it]Loading checkpoint shards: 100%|██████████| 7/7 [00:15<00:00,  1.41s/it]Loading checkpoint shards: 100%|██████████| 7/7 [00:15<00:00,  2.25s/it]
Loading checkpoint shards: 100%|██████████| 7/7 [00:15<00:00,  1.39s/it]Loading checkpoint shards: 100%|██████████| 7/7 [00:15<00:00,  2.19s/it]
WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:217: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate_weight = torch.load(f"{weight_path}/layer_{i}_gate.pt").to(gpu_idx)

W0115 20:11:29.589558 3489877 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:217: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate_weight = torch.load(f"{weight_path}/layer_{i}_gate.pt").to(gpu_idx)

Wrapping layer 1 / 28 from mlp to fMoE
WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:217: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate_weight = torch.load(f"{weight_path}/layer_{i}_gate.pt").to(gpu_idx)

W0115 20:11:31.817572 3489876 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:217: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate_weight = torch.load(f"{weight_path}/layer_{i}_gate.pt").to(gpu_idx)

[rank0]: Traceback (most recent call last):
[rank0]:   File "/data/home/wjbang/workspace/pMoE/pMoE/main.py", line 409, in <module>
[rank0]:     fmoe_time = baseline(args, mesh_shape=mesh_shape, mesh_dims=mesh_dims, dataloader=dataloader, iteration=10000)
[rank0]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/data/home/wjbang/workspace/pMoE/pMoE/main.py", line 368, in baseline
[rank0]:     raise e
[rank0]:   File "/data/home/wjbang/workspace/pMoE/pMoE/main.py", line 284, in baseline
[rank0]:     model = deepseek_wrapper(model, "fMoE", {"total_experts": num_experts, "d_model": 2048, "d_hidden": 1408, "top_k": 2, "world_size": world_size, "moe_group": group}, ctx, gpu_rank, gpu_idx).to(gpu_idx)
[rank0]:             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank0]:     return func(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py", line 218, in deepseek_wrapper
[rank0]:     model.model.layers[i].mlp.gate.gate.weight.copy_(gate_weight)
[rank0]: RuntimeError: The size of tensor a (8) must match the size of tensor b (64) at non-singleton dimension 0
[rank1]: Traceback (most recent call last):
[rank1]:   File "/data/home/wjbang/workspace/pMoE/pMoE/main.py", line 409, in <module>
[rank1]:     fmoe_time = baseline(args, mesh_shape=mesh_shape, mesh_dims=mesh_dims, dataloader=dataloader, iteration=10000)
[rank1]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/data/home/wjbang/workspace/pMoE/pMoE/main.py", line 368, in baseline
[rank1]:     raise e
[rank1]:   File "/data/home/wjbang/workspace/pMoE/pMoE/main.py", line 284, in baseline
[rank1]:     model = deepseek_wrapper(model, "fMoE", {"total_experts": num_experts, "d_model": 2048, "d_hidden": 1408, "top_k": 2, "world_size": world_size, "moe_group": group}, ctx, gpu_rank, gpu_idx).to(gpu_idx)
[rank1]:             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank1]:     return func(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py", line 218, in deepseek_wrapper
[rank1]:     model.model.layers[i].mlp.gate.gate.weight.copy_(gate_weight)
[rank1]: RuntimeError: The size of tensor a (8) must match the size of tensor b (64) at non-singleton dimension 0
W0115 20:11:33.336000 140091327526720 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 3489877 closing signal SIGTERM
E0115 20:11:34.753000 140091327526720 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 0 (pid: 3489876) of binary: /home/wjbang/anaconda3/envs/shan_cuda12.1/bin/python
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/distributed/run.py", line 905, in <module>
    main()
  File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 348, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/distributed/run.py", line 901, in main
    run(args)
  File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-01-15_20:11:33
  host      : gpu-1.novalocal
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 3489876)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
gpuidx: 0 with rank: 0 with world size: 2
initialized the distributed DNN
gpuidx: 1 with rank: 1 with world size: 2
Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:01<00:07,  1.25s/it]Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  29%|██▊       | 2/7 [00:02<00:06,  1.28s/it]Loading checkpoint shards:  14%|█▍        | 1/7 [00:01<00:07,  1.27s/it]Loading checkpoint shards:  43%|████▎     | 3/7 [00:03<00:05,  1.30s/it]Loading checkpoint shards:  29%|██▊       | 2/7 [00:02<00:06,  1.29s/it]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:05<00:03,  1.30s/it]Loading checkpoint shards:  43%|████▎     | 3/7 [00:03<00:05,  1.35s/it]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:06<00:02,  1.31s/it]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:05<00:04,  1.37s/it]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:07<00:01,  1.30s/it]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:06<00:02,  1.39s/it]Loading checkpoint shards: 100%|██████████| 7/7 [00:08<00:00,  1.10s/it]Loading checkpoint shards: 100%|██████████| 7/7 [00:08<00:00,  1.21s/it]
Loading checkpoint shards:  86%|████████▌ | 6/7 [00:08<00:01,  1.39s/it]Loading checkpoint shards: 100%|██████████| 7/7 [00:09<00:00,  1.19s/it]Loading checkpoint shards: 100%|██████████| 7/7 [00:09<00:00,  1.29s/it]
Wrapping layer 1 / 28 from mlp to fMoE
WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:217: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate_weight = torch.load(f"{weight_path}/layer_{i}_gate.pt").to(gpu_idx)

W0115 20:13:55.168225 3492283 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:217: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate_weight = torch.load(f"{weight_path}/layer_{i}_gate.pt").to(gpu_idx)

[rank0]: Traceback (most recent call last):
[rank0]:   File "/data/home/wjbang/workspace/pMoE/pMoE/main.py", line 409, in <module>
[rank0]:     fmoe_time = baseline(args, mesh_shape=mesh_shape, mesh_dims=mesh_dims, dataloader=dataloader, iteration=10000)
[rank0]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/data/home/wjbang/workspace/pMoE/pMoE/main.py", line 368, in baseline
[rank0]:     raise e
[rank0]:   File "/data/home/wjbang/workspace/pMoE/pMoE/main.py", line 284, in baseline
[rank0]:     model = deepseek_wrapper(model, "fMoE", {"total_experts": num_experts, "d_model": 2048, "d_hidden": 1408, "top_k": 2, "world_size": world_size, "moe_group": group}, ctx, gpu_rank, gpu_idx).to(gpu_idx)
[rank0]:             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank0]:     return func(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py", line 219, in deepseek_wrapper
[rank0]:     del gate
[rank0]:         ^^^^
[rank0]: UnboundLocalError: cannot access local variable 'gate' where it is not associated with a value
W0115 20:13:57.617000 140703898859328 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 3492284 closing signal SIGTERM
E0115 20:13:58.332000 140703898859328 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 0 (pid: 3492283) of binary: /home/wjbang/anaconda3/envs/shan_cuda12.1/bin/python
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/distributed/run.py", line 905, in <module>
    main()
  File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 348, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/distributed/run.py", line 901, in main
    run(args)
  File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-01-15_20:13:57
  host      : gpu-1.novalocal
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 3492283)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
gpuidx: 1 with rank: 1 with world size: 2
gpuidx: 0 with rank: 0 with world size: 2
initialized the distributed DNN
Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:01<00:08,  1.43s/it]Loading checkpoint shards:  14%|█▍        | 1/7 [00:01<00:08,  1.37s/it]Loading checkpoint shards:  29%|██▊       | 2/7 [00:02<00:06,  1.38s/it]Loading checkpoint shards:  29%|██▊       | 2/7 [00:02<00:07,  1.44s/it]Loading checkpoint shards:  43%|████▎     | 3/7 [00:04<00:05,  1.40s/it]Loading checkpoint shards:  43%|████▎     | 3/7 [00:04<00:05,  1.45s/it]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:05<00:04,  1.41s/it]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:05<00:04,  1.46s/it]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:07<00:02,  1.45s/it]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:07<00:02,  1.46s/it]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:08<00:01,  1.47s/it]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:08<00:01,  1.51s/it]Loading checkpoint shards: 100%|██████████| 7/7 [00:09<00:00,  1.26s/it]Loading checkpoint shards: 100%|██████████| 7/7 [00:09<00:00,  1.37s/it]
Loading checkpoint shards: 100%|██████████| 7/7 [00:09<00:00,  1.30s/it]Loading checkpoint shards: 100%|██████████| 7/7 [00:09<00:00,  1.37s/it]
Wrapping layer 1 / 28 from mlp to fMoE
WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:217: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate_weight = torch.load(f"{weight_path}/layer_{i}_gate.pt").to(gpu_idx)

W0115 20:15:50.802042 3493403 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:217: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate_weight = torch.load(f"{weight_path}/layer_{i}_gate.pt").to(gpu_idx)

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:217: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate_weight = torch.load(f"{weight_path}/layer_{i}_gate.pt").to(gpu_idx)

W0115 20:15:50.838318 3493404 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:217: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate_weight = torch.load(f"{weight_path}/layer_{i}_gate.pt").to(gpu_idx)

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:227: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  up_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_up.pt")

W0115 20:15:51.143948 3493403 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:227: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  up_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_up.pt")

[rank0]: Traceback (most recent call last):
[rank0]:   File "/data/home/wjbang/workspace/pMoE/pMoE/main.py", line 409, in <module>
[rank0]:     fmoe_time = baseline(args, mesh_shape=mesh_shape, mesh_dims=mesh_dims, dataloader=dataloader, iteration=10000)
[rank0]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/data/home/wjbang/workspace/pMoE/pMoE/main.py", line 368, in baseline
[rank0]:     raise e
[rank0]:   File "/data/home/wjbang/workspace/pMoE/pMoE/main.py", line 284, in baseline
[rank0]:     model = deepseek_wrapper(model, "fMoE", {"total_experts": num_experts, "d_model": 2048, "d_hidden": 1408, "top_k": 2, "world_size": world_size, "moe_group": group}, ctx, gpu_rank, gpu_idx).to(gpu_idx)
[rank0]:             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank0]:     return func(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py", line 227, in deepseek_wrapper
[rank0]:     up_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_up.pt")
[rank0]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/serialization.py", line 1065, in load
[rank0]:     with _open_file_like(f, 'rb') as opened_file:
[rank0]:          ^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/serialization.py", line 468, in _open_file_like
[rank0]:     return _open_file(name_or_buffer, mode)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/serialization.py", line 449, in __init__
[rank0]:     super().__init__(open(name, mode))
[rank0]:                      ^^^^^^^^^^^^^^^^
[rank0]: FileNotFoundError: [Errno 2] No such file or directory: '/home/wjbang/workspace/pMoE/pMoE/models/models_weight/deepseek-moe-16b-chat/layer_1_expert_0_up.pt'
W0115 20:15:53.086000 139769661060928 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 3493404 closing signal SIGTERM
E0115 20:15:54.052000 139769661060928 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 0 (pid: 3493403) of binary: /home/wjbang/anaconda3/envs/shan_cuda12.1/bin/python
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/distributed/run.py", line 905, in <module>
    main()
  File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 348, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/distributed/run.py", line 901, in main
    run(args)
  File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-01-15_20:15:53
  host      : gpu-1.novalocal
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 3493403)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
gpuidx: 1 with rank: 1 with world size: 2
gpuidx: 0 with rank: 0 with world size: 2
initialized the distributed DNN
Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:01<00:07,  1.27s/it]Loading checkpoint shards:  14%|█▍        | 1/7 [00:01<00:08,  1.37s/it]Loading checkpoint shards:  29%|██▊       | 2/7 [00:02<00:06,  1.29s/it]Loading checkpoint shards:  29%|██▊       | 2/7 [00:02<00:06,  1.38s/it]Loading checkpoint shards:  43%|████▎     | 3/7 [00:04<00:05,  1.38s/it]Loading checkpoint shards:  43%|████▎     | 3/7 [00:04<00:05,  1.38s/it]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:05<00:04,  1.39s/it]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:05<00:04,  1.38s/it]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:06<00:02,  1.39s/it]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:06<00:02,  1.38s/it]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:08<00:01,  1.38s/it]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:08<00:01,  1.38s/it]Loading checkpoint shards: 100%|██████████| 7/7 [00:08<00:00,  1.17s/it]Loading checkpoint shards: 100%|██████████| 7/7 [00:08<00:00,  1.28s/it]
Loading checkpoint shards: 100%|██████████| 7/7 [00:09<00:00,  1.18s/it]Loading checkpoint shards: 100%|██████████| 7/7 [00:09<00:00,  1.29s/it]
Wrapping layer 1 / 28 from mlp to fMoE
WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:217: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate_weight = torch.load(f"{weight_path}/layer_{i}_gate.pt").to(gpu_idx)

W0115 20:18:26.788461 3494238 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:217: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate_weight = torch.load(f"{weight_path}/layer_{i}_gate.pt").to(gpu_idx)

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:227: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  up_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_up_proj.pt")

W0115 20:18:28.539500 3494238 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:227: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  up_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_up_proj.pt")

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:228: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  down_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_down_proj.pt")

W0115 20:18:28.958873 3494238 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:228: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  down_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_down_proj.pt")

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:229: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_gate_proj.pt")

W0115 20:18:29.001395 3494238 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:229: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_gate_proj.pt")

[rank0]: Traceback (most recent call last):
[rank0]:   File "/data/home/wjbang/workspace/pMoE/pMoE/main.py", line 409, in <module>
[rank0]:     fmoe_time = baseline(args, mesh_shape=mesh_shape, mesh_dims=mesh_dims, dataloader=dataloader, iteration=10000)
[rank0]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/data/home/wjbang/workspace/pMoE/pMoE/main.py", line 368, in baseline
[rank0]:     raise e
[rank0]:   File "/data/home/wjbang/workspace/pMoE/pMoE/main.py", line 284, in baseline
[rank0]:     model = deepseek_wrapper(model, "fMoE", {"total_experts": num_experts, "d_model": 2048, "d_hidden": 1408, "top_k": 2, "world_size": world_size, "moe_group": group}, ctx, gpu_rank, gpu_idx).to(gpu_idx)
[rank0]:             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank0]:     return func(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py", line 232, in deepseek_wrapper
[rank0]:     model.model.layers[i].mlp.experts[idx].down_proj.weight.copy_(down_weight)
[rank0]: RuntimeError: The size of tensor a (2048) must match the size of tensor b (1408) at non-singleton dimension 2
WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:217: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate_weight = torch.load(f"{weight_path}/layer_{i}_gate.pt").to(gpu_idx)

W0115 20:18:29.287814 3494239 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:217: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate_weight = torch.load(f"{weight_path}/layer_{i}_gate.pt").to(gpu_idx)

W0115 20:18:30.724000 139871669081920 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 3494239 closing signal SIGTERM
E0115 20:18:32.391000 139871669081920 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 0 (pid: 3494238) of binary: /home/wjbang/anaconda3/envs/shan_cuda12.1/bin/python
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/distributed/run.py", line 905, in <module>
    main()
  File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 348, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/distributed/run.py", line 901, in main
    run(args)
  File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-01-15_20:18:30
  host      : gpu-1.novalocal
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 3494238)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
gpuidx: 0 with rank: 0 with world size: 2
initialized the distributed DNN
gpuidx: 1 with rank: 1 with world size: 2
Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:01<00:07,  1.29s/it]Loading checkpoint shards:  14%|█▍        | 1/7 [00:01<00:07,  1.29s/it]Loading checkpoint shards:  29%|██▊       | 2/7 [00:02<00:06,  1.32s/it]Loading checkpoint shards:  29%|██▊       | 2/7 [00:02<00:06,  1.32s/it]Loading checkpoint shards:  43%|████▎     | 3/7 [00:03<00:05,  1.34s/it]Loading checkpoint shards:  43%|████▎     | 3/7 [00:03<00:05,  1.33s/it]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:09<00:09,  3.12s/it]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:09<00:09,  3.17s/it]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:15<00:08,  4.15s/it]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:15<00:08,  4.13s/it]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:17<00:03,  3.19s/it]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:17<00:03,  3.18s/it]Loading checkpoint shards: 100%|██████████| 7/7 [00:17<00:00,  2.37s/it]Loading checkpoint shards: 100%|██████████| 7/7 [00:17<00:00,  2.55s/it]
Loading checkpoint shards: 100%|██████████| 7/7 [00:17<00:00,  2.37s/it]Loading checkpoint shards: 100%|██████████| 7/7 [00:17<00:00,  2.55s/it]
Wrapping layer 1 / 28 from mlp to fMoE
WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:217: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate_weight = torch.load(f"{weight_path}/layer_{i}_gate.pt").to(gpu_idx)

W0115 20:47:07.821611 3501551 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:217: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate_weight = torch.load(f"{weight_path}/layer_{i}_gate.pt").to(gpu_idx)

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:217: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate_weight = torch.load(f"{weight_path}/layer_{i}_gate.pt").to(gpu_idx)

W0115 20:47:07.888682 3501552 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:217: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate_weight = torch.load(f"{weight_path}/layer_{i}_gate.pt").to(gpu_idx)

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:227: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  up_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_up_proj.pt")

W0115 20:47:09.002700 3501551 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:227: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  up_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_up_proj.pt")

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:228: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  down_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_down_proj.pt")

W0115 20:47:09.055910 3501551 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:228: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  down_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_down_proj.pt")

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:229: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_gate_proj.pt")

W0115 20:47:09.110461 3501551 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:229: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_gate_proj.pt")

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:227: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  up_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_up_proj.pt")

W0115 20:47:11.551670 3501552 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:227: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  up_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_up_proj.pt")

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:228: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  down_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_down_proj.pt")

W0115 20:47:11.611210 3501552 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:228: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  down_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_down_proj.pt")

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:229: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_gate_proj.pt")

W0115 20:47:11.672125 3501552 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:229: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_gate_proj.pt")

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:239: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  shared_expert_weight = torch.load(f"{weight_path}/layer_{i}_shared_experts.pt") # state_dict

W0115 20:47:22.296858 3501551 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:239: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  shared_expert_weight = torch.load(f"{weight_path}/layer_{i}_shared_experts.pt") # state_dict

Wrapping layer 2 / 28 from mlp to fMoE
WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:239: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  shared_expert_weight = torch.load(f"{weight_path}/layer_{i}_shared_experts.pt") # state_dict

W0115 20:47:25.795212 3501552 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:239: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  shared_expert_weight = torch.load(f"{weight_path}/layer_{i}_shared_experts.pt") # state_dict

Wrapping layer 3 / 28 from mlp to fMoE
Wrapping layer 4 / 28 from mlp to fMoE
Wrapping layer 5 / 28 from mlp to fMoE
Wrapping layer 6 / 28 from mlp to fMoE
Wrapping layer 7 / 28 from mlp to fMoE
Wrapping layer 8 / 28 from mlp to fMoE
Wrapping layer 9 / 28 from mlp to fMoE
Wrapping layer 10 / 28 from mlp to fMoE
Wrapping layer 11 / 28 from mlp to fMoE
Wrapping layer 12 / 28 from mlp to fMoE
Wrapping layer 13 / 28 from mlp to fMoE
Wrapping layer 14 / 28 from mlp to fMoE
Wrapping layer 15 / 28 from mlp to fMoE
Wrapping layer 16 / 28 from mlp to fMoE
Wrapping layer 17 / 28 from mlp to fMoE
Wrapping layer 18 / 28 from mlp to fMoE
Wrapping layer 19 / 28 from mlp to fMoE
Wrapping layer 20 / 28 from mlp to fMoE
Wrapping layer 21 / 28 from mlp to fMoE
Wrapping layer 22 / 28 from mlp to fMoE
Wrapping layer 23 / 28 from mlp to fMoE
Wrapping layer 24 / 28 from mlp to fMoE
Wrapping layer 25 / 28 from mlp to fMoE
Wrapping layer 26 / 28 from mlp to fMoE
Wrapping layer 27 / 28 from mlp to fMoE
processing 0th data
[rank0]: Traceback (most recent call last):
[rank0]:   File "/data/home/wjbang/workspace/pMoE/pMoE/main.py", line 409, in <module>
[rank0]:     fmoe_time = baseline(args, mesh_shape=mesh_shape, mesh_dims=mesh_dims, dataloader=dataloader, iteration=1000)
[rank0]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/data/home/wjbang/workspace/pMoE/pMoE/main.py", line 368, in baseline
[rank0]:     raise e
[rank0]:   File "/data/home/wjbang/workspace/pMoE/pMoE/main.py", line 343, in baseline
[rank0]:     gate_data = model.model.layers[idx].block_sparse_moe.save_gate_data
[rank0]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1729, in __getattr__
[rank0]:     raise AttributeError(f"'{type(self).__name__}' object has no attribute '{name}'")
[rank0]: AttributeError: 'DeepseekDecoderLayer' object has no attribute 'block_sparse_moe'
W0115 20:55:41.314000 140476624795456 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 3501552 closing signal SIGTERM
E0115 20:55:45.449000 140476624795456 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 0 (pid: 3501551) of binary: /home/wjbang/anaconda3/envs/shan_cuda12.1/bin/python
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/distributed/run.py", line 905, in <module>
    main()
  File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 348, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/distributed/run.py", line 901, in main
    run(args)
  File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-01-15_20:55:41
  host      : gpu-1.novalocal
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 3501551)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
gpuidx: 0 with rank: 0 with world size: 2
initialized the distributed DNN
gpuidx: 1 with rank: 1 with world size: 2
Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:01<00:08,  1.36s/it]Loading checkpoint shards:  14%|█▍        | 1/7 [00:01<00:08,  1.36s/it]Loading checkpoint shards:  29%|██▊       | 2/7 [00:02<00:06,  1.39s/it]Loading checkpoint shards:  29%|██▊       | 2/7 [00:02<00:06,  1.39s/it]Loading checkpoint shards:  43%|████▎     | 3/7 [00:04<00:05,  1.39s/it]Loading checkpoint shards:  43%|████▎     | 3/7 [00:04<00:05,  1.42s/it]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:05<00:04,  1.41s/it]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:05<00:04,  1.41s/it]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:07<00:02,  1.41s/it]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:06<00:02,  1.39s/it]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:08<00:01,  1.41s/it]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:08<00:01,  1.37s/it]Loading checkpoint shards: 100%|██████████| 7/7 [00:09<00:00,  1.21s/it]Loading checkpoint shards: 100%|██████████| 7/7 [00:09<00:00,  1.32s/it]
Loading checkpoint shards: 100%|██████████| 7/7 [00:09<00:00,  1.15s/it]Loading checkpoint shards: 100%|██████████| 7/7 [00:09<00:00,  1.29s/it]
WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:217: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate_weight = torch.load(f"{weight_path}/layer_{i}_gate.pt").to(gpu_idx)

W0115 21:00:26.391619 3506317 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:217: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate_weight = torch.load(f"{weight_path}/layer_{i}_gate.pt").to(gpu_idx)

Wrapping layer 1 / 28 from mlp to fMoE
WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:227: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  up_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_up_proj.pt")

W0115 21:00:29.085798 3506317 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:227: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  up_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_up_proj.pt")

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:228: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  down_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_down_proj.pt")

W0115 21:00:29.095856 3506317 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:228: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  down_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_down_proj.pt")

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:229: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_gate_proj.pt")

W0115 21:00:29.100614 3506317 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:229: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_gate_proj.pt")

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:217: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate_weight = torch.load(f"{weight_path}/layer_{i}_gate.pt").to(gpu_idx)

W0115 21:00:31.086238 3506316 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:217: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate_weight = torch.load(f"{weight_path}/layer_{i}_gate.pt").to(gpu_idx)

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:227: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  up_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_up_proj.pt")

W0115 21:00:32.113488 3506316 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:227: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  up_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_up_proj.pt")

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:228: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  down_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_down_proj.pt")

W0115 21:00:32.123964 3506316 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:228: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  down_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_down_proj.pt")

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:229: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_gate_proj.pt")

W0115 21:00:32.127204 3506316 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:229: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_gate_proj.pt")

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:239: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  shared_expert_weight = torch.load(f"{weight_path}/layer_{i}_shared_experts.pt") # state_dict

W0115 21:00:41.280686 3506316 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:239: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  shared_expert_weight = torch.load(f"{weight_path}/layer_{i}_shared_experts.pt") # state_dict

Wrapping layer 2 / 28 from mlp to fMoE
WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:239: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  shared_expert_weight = torch.load(f"{weight_path}/layer_{i}_shared_experts.pt") # state_dict

W0115 21:00:42.496655 3506317 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:239: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  shared_expert_weight = torch.load(f"{weight_path}/layer_{i}_shared_experts.pt") # state_dict

Wrapping layer 3 / 28 from mlp to fMoE
Wrapping layer 4 / 28 from mlp to fMoE
Wrapping layer 5 / 28 from mlp to fMoE
Wrapping layer 6 / 28 from mlp to fMoE
Wrapping layer 7 / 28 from mlp to fMoE
Wrapping layer 8 / 28 from mlp to fMoE
Wrapping layer 9 / 28 from mlp to fMoE
Wrapping layer 10 / 28 from mlp to fMoE
Wrapping layer 11 / 28 from mlp to fMoE
Wrapping layer 12 / 28 from mlp to fMoE
Wrapping layer 13 / 28 from mlp to fMoE
Wrapping layer 14 / 28 from mlp to fMoE
Wrapping layer 15 / 28 from mlp to fMoE
Wrapping layer 16 / 28 from mlp to fMoE
Wrapping layer 17 / 28 from mlp to fMoE
Wrapping layer 18 / 28 from mlp to fMoE
Wrapping layer 19 / 28 from mlp to fMoE
Wrapping layer 20 / 28 from mlp to fMoE
Wrapping layer 21 / 28 from mlp to fMoE
Wrapping layer 22 / 28 from mlp to fMoE
Wrapping layer 23 / 28 from mlp to fMoE
Wrapping layer 24 / 28 from mlp to fMoE
Wrapping layer 25 / 28 from mlp to fMoE
Wrapping layer 26 / 28 from mlp to fMoE
Wrapping layer 27 / 28 from mlp to fMoE
processing 0th data
[rank0]: Traceback (most recent call last):
[rank0]:   File "/data/home/wjbang/workspace/pMoE/pMoE/main.py", line 409, in <module>
[rank0]:     fmoe_time = baseline(args, mesh_shape=mesh_shape, mesh_dims=mesh_dims, dataloader=dataloader, iteration=1000)
[rank0]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/data/home/wjbang/workspace/pMoE/pMoE/main.py", line 368, in baseline
[rank0]:     raise e
[rank0]:   File "/data/home/wjbang/workspace/pMoE/pMoE/main.py", line 343, in baseline
[rank0]:     gate_data = model.model.layers[idx].mlp.save_gate_data
[rank0]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1729, in __getattr__
[rank0]:     raise AttributeError(f"'{type(self).__name__}' object has no attribute '{name}'")
[rank0]: AttributeError: 'DeepseekMLP' object has no attribute 'save_gate_data'
W0115 21:07:16.709000 140628510095168 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 3506317 closing signal SIGTERM
E0115 21:07:21.032000 140628510095168 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 0 (pid: 3506316) of binary: /home/wjbang/anaconda3/envs/shan_cuda12.1/bin/python
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/distributed/run.py", line 905, in <module>
    main()
  File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 348, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/distributed/run.py", line 901, in main
    run(args)
  File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-01-15_21:07:16
  host      : gpu-1.novalocal
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 3506316)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
gpuidx: 0 with rank: 0 with world size: 2
initialized the distributed DNN
gpuidx: 1 with rank: 1 with world size: 2
Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:01<00:08,  1.36s/it]Loading checkpoint shards:  14%|█▍        | 1/7 [00:01<00:08,  1.44s/it]Loading checkpoint shards:  29%|██▊       | 2/7 [00:02<00:06,  1.39s/it]Loading checkpoint shards:  29%|██▊       | 2/7 [00:02<00:07,  1.43s/it]Loading checkpoint shards:  43%|████▎     | 3/7 [00:04<00:05,  1.38s/it]Loading checkpoint shards:  43%|████▎     | 3/7 [00:04<00:05,  1.44s/it]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:05<00:04,  1.38s/it]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:05<00:04,  1.44s/it]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:06<00:02,  1.37s/it]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:07<00:02,  1.43s/it]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:08<00:01,  1.36s/it]Loading checkpoint shards: 100%|██████████| 7/7 [00:09<00:00,  1.18s/it]Loading checkpoint shards: 100%|██████████| 7/7 [00:09<00:00,  1.29s/it]
Loading checkpoint shards:  86%|████████▌ | 6/7 [00:08<00:01,  1.43s/it]Loading checkpoint shards: 100%|██████████| 7/7 [00:09<00:00,  1.22s/it]Loading checkpoint shards: 100%|██████████| 7/7 [00:09<00:00,  1.34s/it]
Wrapping layer 1 / 28 from mlp to fMoE
WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:217: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate_weight = torch.load(f"{weight_path}/layer_{i}_gate.pt").to(gpu_idx)

W0115 21:26:14.341013 3512634 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:217: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate_weight = torch.load(f"{weight_path}/layer_{i}_gate.pt").to(gpu_idx)

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:217: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate_weight = torch.load(f"{weight_path}/layer_{i}_gate.pt").to(gpu_idx)

W0115 21:26:14.379343 3512633 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:217: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate_weight = torch.load(f"{weight_path}/layer_{i}_gate.pt").to(gpu_idx)

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:227: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  up_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_up_proj.pt")

W0115 21:26:15.700540 3512633 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:227: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  up_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_up_proj.pt")

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:228: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  down_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_down_proj.pt")

W0115 21:26:15.748338 3512633 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:228: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  down_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_down_proj.pt")

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:229: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_gate_proj.pt")

W0115 21:26:15.790175 3512633 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:229: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_gate_proj.pt")

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:227: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  up_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_up_proj.pt")

W0115 21:26:18.876258 3512634 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:227: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  up_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_up_proj.pt")

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:228: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  down_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_down_proj.pt")

W0115 21:26:19.522486 3512634 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:228: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  down_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_down_proj.pt")

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:229: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_gate_proj.pt")

W0115 21:26:19.566525 3512634 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:229: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_gate_proj.pt")

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:239: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  shared_expert_weight = torch.load(f"{weight_path}/layer_{i}_shared_experts.pt") # state_dict

W0115 21:26:28.842378 3512633 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:239: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  shared_expert_weight = torch.load(f"{weight_path}/layer_{i}_shared_experts.pt") # state_dict

Wrapping layer 2 / 28 from mlp to fMoE
WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:239: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  shared_expert_weight = torch.load(f"{weight_path}/layer_{i}_shared_experts.pt") # state_dict

W0115 21:26:33.866808 3512634 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:239: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  shared_expert_weight = torch.load(f"{weight_path}/layer_{i}_shared_experts.pt") # state_dict

Wrapping layer 3 / 28 from mlp to fMoE
Wrapping layer 4 / 28 from mlp to fMoE
Wrapping layer 5 / 28 from mlp to fMoE
Wrapping layer 6 / 28 from mlp to fMoE
Wrapping layer 7 / 28 from mlp to fMoE
Wrapping layer 8 / 28 from mlp to fMoE
Wrapping layer 9 / 28 from mlp to fMoE
Wrapping layer 10 / 28 from mlp to fMoE
Wrapping layer 11 / 28 from mlp to fMoE
Wrapping layer 12 / 28 from mlp to fMoE
Wrapping layer 13 / 28 from mlp to fMoE
Wrapping layer 14 / 28 from mlp to fMoE
Wrapping layer 15 / 28 from mlp to fMoE
Wrapping layer 16 / 28 from mlp to fMoE
Wrapping layer 17 / 28 from mlp to fMoE
Wrapping layer 18 / 28 from mlp to fMoE
Wrapping layer 19 / 28 from mlp to fMoE
Wrapping layer 20 / 28 from mlp to fMoE
Wrapping layer 21 / 28 from mlp to fMoE
Wrapping layer 22 / 28 from mlp to fMoE
Wrapping layer 23 / 28 from mlp to fMoE
Wrapping layer 24 / 28 from mlp to fMoE
Wrapping layer 25 / 28 from mlp to fMoE
Wrapping layer 26 / 28 from mlp to fMoE
Wrapping layer 27 / 28 from mlp to fMoE
processing 0th data
processing 10th data
processing 20th data
processing 30th data
processing 40th data
processing 50th data
processing 60th data
processing 70th data
processing 80th data
processing 90th data
processing 100th data
processing 110th data
processing 120th data
processing 130th data
processing 140th data
processing 150th data
processing 160th data
processing 170th data
processing 180th data
processing 190th data
processing 200th data
processing 210th data
processing 220th data
processing 230th data
processing 240th data
processing 250th data
processing 260th data
processing 270th data
processing 280th data
processing 290th data
processing 300th data
processing 310th data
processing 320th data
processing 330th data
processing 340th data
processing 350th data
processing 360th data
processing 370th data
processing 380th data
processing 390th data
processing 400th data
processing 410th data
processing 420th data
processing 430th data
processing 440th data
processing 450th data
processing 460th data
processing 470th data
processing 480th data
processing 490th data
processing 500th data
processing 510th data
processing 520th data
processing 530th data
processing 540th data
processing 550th data
processing 560th data
processing 570th data
processing 580th data
processing 590th data
processing 600th data
processing 610th data
processing 620th data
processing 630th data
processing 640th data
processing 650th data
processing 660th data
processing 670th data
processing 680th data
processing 690th data
processing 700th data
processing 710th data
processing 720th data
processing 730th data
processing 740th data
processing 750th data
processing 760th data
processing 770th data
processing 780th data
processing 790th data
processing 800th data
processing 810th data
processing 820th data
processing 830th data
processing 840th data
processing 850th data
processing 860th data
processing 870th data
processing 880th data
processing 890th data
processing 900th data
processing 910th data
processing 920th data
processing 930th data
processing 940th data
processing 950th data
processing 960th data
processing 970th data
processing 980th data
processing 990th data
processing 1000th data
FMOE: [Rank 1] Average Elapsed Time: 256.2415207977295ms 

FMOE: [Rank 0] Average Elapsed Time: 256.0938392486572ms 

gpuidx: 0 with rank: 0 with world size: 2
initialized the distributed DNN
gpuidx: 1 with rank: 1 with world size: 2
Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:02<00:14,  2.49s/it]Loading checkpoint shards:  14%|█▍        | 1/7 [00:02<00:14,  2.49s/it]Loading checkpoint shards:  29%|██▊       | 2/7 [00:05<00:13,  2.70s/it]Loading checkpoint shards:  29%|██▊       | 2/7 [00:05<00:13,  2.72s/it]Loading checkpoint shards:  43%|████▎     | 3/7 [00:08<00:11,  2.79s/it]Loading checkpoint shards:  43%|████▎     | 3/7 [00:08<00:11,  2.80s/it]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:10<00:07,  2.65s/it]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:10<00:07,  2.64s/it]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:13<00:05,  2.56s/it]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:13<00:05,  2.57s/it]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:15<00:02,  2.53s/it]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:15<00:02,  2.54s/it]Loading checkpoint shards: 100%|██████████| 7/7 [00:16<00:00,  2.17s/it]Loading checkpoint shards: 100%|██████████| 7/7 [00:16<00:00,  2.42s/it]
Loading checkpoint shards: 100%|██████████| 7/7 [00:17<00:00,  2.18s/it]Loading checkpoint shards: 100%|██████████| 7/7 [00:17<00:00,  2.43s/it]
[rank1]: Traceback (most recent call last):
[rank1]:   File "/data/home/wjbang/workspace/pMoE/pMoE/main.py", line 409, in <module>
[rank1]:     fmoe_time = baseline(args, mesh_shape=mesh_shape, mesh_dims=mesh_dims, dataloader=dataloader, iteration=1000)
[rank1]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/data/home/wjbang/workspace/pMoE/pMoE/main.py", line 368, in baseline
[rank1]:     raise e
[rank1]:   File "/data/home/wjbang/workspace/pMoE/pMoE/main.py", line 283, in baseline
[rank1]:     model = load_deepseek(gpu_idx)
[rank1]:             ^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank1]:     return func(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py", line 265, in load_deepseek
[rank1]:     model = AutoModelForCausalLM.from_pretrained(model_name, device_map=None, torch_dtype=torch.bfloat16, trust_remote_code=True).to(gpu_idx)
[rank1]:             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/transformers/modeling_utils.py", line 3164, in to
[rank1]:     return super().to(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1174, in to
[rank1]:     return self._apply(convert)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/nn/modules/module.py", line 780, in _apply
[rank1]:     module._apply(fn)
[rank1]:   File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/nn/modules/module.py", line 780, in _apply
[rank1]:     module._apply(fn)
[rank1]:   File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/nn/modules/module.py", line 780, in _apply
[rank1]:     module._apply(fn)
[rank1]:   [Previous line repeated 4 more times]
[rank1]:   File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/nn/modules/module.py", line 805, in _apply
[rank1]:     param_applied = fn(param)
[rank1]:                     ^^^^^^^^^
[rank1]:   File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1160, in convert
[rank1]:     return t.to(
[rank1]:            ^^^^^
[rank1]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 79.15 GiB of which 10.12 MiB is free. Process 3598896 has 65.07 GiB memory in use. Including non-PyTorch memory, this process has 14.06 GiB memory in use. Of the allocated memory 11.40 GiB is allocated by PyTorch, and 2.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
W0116 12:43:07.985000 140068489807680 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 3697748 closing signal SIGTERM
E0116 12:43:08.800000 140068489807680 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 1 (pid: 3697749) of binary: /home/wjbang/anaconda3/envs/shan_cuda12.1/bin/python
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/distributed/run.py", line 905, in <module>
    main()
  File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 348, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/distributed/run.py", line 901, in main
    run(args)
  File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/wjbang/anaconda3/envs/shan_cuda12.1/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-01-16_12:43:07
  host      : gpu-1.novalocal
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 3697749)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
gpuidx: 0 with rank: 0 with world size: 2
initialized the distributed DNN
gpuidx: 1 with rank: 1 with world size: 2
Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:01<00:07,  1.33s/it]Loading checkpoint shards:  14%|█▍        | 1/7 [00:01<00:08,  1.35s/it]Loading checkpoint shards:  29%|██▊       | 2/7 [00:02<00:06,  1.36s/it]Loading checkpoint shards:  29%|██▊       | 2/7 [00:02<00:06,  1.37s/it]Loading checkpoint shards:  43%|████▎     | 3/7 [00:04<00:05,  1.36s/it]Loading checkpoint shards:  43%|████▎     | 3/7 [00:04<00:05,  1.37s/it]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:05<00:04,  1.37s/it]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:05<00:04,  1.37s/it]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:06<00:02,  1.37s/it]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:06<00:02,  1.38s/it]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:08<00:01,  1.37s/it]Loading checkpoint shards: 100%|██████████| 7/7 [00:08<00:00,  1.17s/it]Loading checkpoint shards: 100%|██████████| 7/7 [00:08<00:00,  1.28s/it]
Loading checkpoint shards:  86%|████████▌ | 6/7 [00:08<00:01,  1.39s/it]Loading checkpoint shards: 100%|██████████| 7/7 [00:09<00:00,  1.18s/it]Loading checkpoint shards: 100%|██████████| 7/7 [00:09<00:00,  1.29s/it]
Wrapping layer 1 / 28 from mlp to fMoE
WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:217: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate_weight = torch.load(f"{weight_path}/layer_{i}_gate.pt").to(gpu_idx)

W0116 12:47:23.645539 3699680 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:217: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate_weight = torch.load(f"{weight_path}/layer_{i}_gate.pt").to(gpu_idx)

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:217: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate_weight = torch.load(f"{weight_path}/layer_{i}_gate.pt").to(gpu_idx)

W0116 12:47:23.887947 3699681 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:217: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate_weight = torch.load(f"{weight_path}/layer_{i}_gate.pt").to(gpu_idx)

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:227: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  up_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_up_proj.pt")

W0116 12:47:24.934227 3699680 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:227: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  up_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_up_proj.pt")

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:228: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  down_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_down_proj.pt")

W0116 12:47:24.984416 3699680 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:228: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  down_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_down_proj.pt")

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:229: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_gate_proj.pt")

W0116 12:47:25.027156 3699680 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:229: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_gate_proj.pt")

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:227: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  up_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_up_proj.pt")

W0116 12:47:25.980821 3699681 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:227: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  up_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_up_proj.pt")

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:228: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  down_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_down_proj.pt")

W0116 12:47:26.033111 3699681 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:228: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  down_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_down_proj.pt")

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:229: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_gate_proj.pt")

W0116 12:47:26.073387 3699681 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:229: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_gate_proj.pt")

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:239: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  shared_expert_weight = torch.load(f"{weight_path}/layer_{i}_shared_experts.pt") # state_dict

W0116 12:47:35.269737 3699680 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:239: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  shared_expert_weight = torch.load(f"{weight_path}/layer_{i}_shared_experts.pt") # state_dict

Wrapping layer 2 / 28 from mlp to fMoE
WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:239: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  shared_expert_weight = torch.load(f"{weight_path}/layer_{i}_shared_experts.pt") # state_dict

W0116 12:47:35.952956 3699681 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:239: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  shared_expert_weight = torch.load(f"{weight_path}/layer_{i}_shared_experts.pt") # state_dict

Wrapping layer 3 / 28 from mlp to fMoE
Wrapping layer 4 / 28 from mlp to fMoE
Wrapping layer 5 / 28 from mlp to fMoE
Wrapping layer 6 / 28 from mlp to fMoE
Wrapping layer 7 / 28 from mlp to fMoE
Wrapping layer 8 / 28 from mlp to fMoE
Wrapping layer 9 / 28 from mlp to fMoE
Wrapping layer 10 / 28 from mlp to fMoE
Wrapping layer 11 / 28 from mlp to fMoE
Wrapping layer 12 / 28 from mlp to fMoE
Wrapping layer 13 / 28 from mlp to fMoE
Wrapping layer 14 / 28 from mlp to fMoE
Wrapping layer 15 / 28 from mlp to fMoE
Wrapping layer 16 / 28 from mlp to fMoE
Wrapping layer 17 / 28 from mlp to fMoE
Wrapping layer 18 / 28 from mlp to fMoE
Wrapping layer 19 / 28 from mlp to fMoE
Wrapping layer 20 / 28 from mlp to fMoE
Wrapping layer 21 / 28 from mlp to fMoE
Wrapping layer 22 / 28 from mlp to fMoE
Wrapping layer 23 / 28 from mlp to fMoE
Wrapping layer 24 / 28 from mlp to fMoE
Wrapping layer 25 / 28 from mlp to fMoE
Wrapping layer 26 / 28 from mlp to fMoE
Wrapping layer 27 / 28 from mlp to fMoE
processing 0th data
processing 10th data
processing 20th data
processing 30th data
processing 40th data
processing 50th data
processing 60th data
processing 70th data
processing 80th data
processing 90th data
processing 100th data
processing 110th data
processing 120th data
processing 130th data
processing 140th data
processing 150th data
processing 160th data
processing 170th data
processing 180th data
processing 190th data
processing 200th data
processing 210th data
processing 220th data
processing 230th data
processing 240th data
processing 250th data
processing 260th data
processing 270th data
processing 280th data
processing 290th data
processing 300th data
processing 310th data
processing 320th data
processing 330th data
processing 340th data
processing 350th data
processing 360th data
processing 370th data
processing 380th data
processing 390th data
processing 400th data
processing 410th data
processing 420th data
processing 430th data
processing 440th data
processing 450th data
processing 460th data
processing 470th data
processing 480th data
processing 490th data
processing 500th data
processing 510th data
processing 520th data
processing 530th data
processing 540th data
processing 550th data
processing 560th data
processing 570th data
processing 580th data
processing 590th data
processing 600th data
processing 610th data
processing 620th data
processing 630th data
processing 640th data
processing 650th data
processing 660th data
processing 670th data
processing 680th data
processing 690th data
processing 700th data
processing 710th data
processing 720th data
processing 730th data
processing 740th data
processing 750th data
processing 760th data
processing 770th data
processing 780th data
processing 790th data
processing 800th data
processing 810th data
processing 820th data
processing 830th data
processing 840th data
processing 850th data
processing 860th data
processing 870th data
processing 880th data
processing 890th data
processing 900th data
processing 910th data
processing 920th data
processing 930th data
processing 940th data
processing 950th data
processing 960th data
processing 970th data
processing 980th data
processing 990th data
FMOE: [Rank 1] Average Elapsed Time: 307.93083378601074ms 

processing 1000th data
FMOE: [Rank 0] Average Elapsed Time: 307.75781842041016ms 

Generating train split:   0%|          | 0/87599 [00:00<?, ? examples/s]Generating train split:   1%|          | 1000/87599 [00:00<00:26, 3315.46 examples/s]Generating train split:  91%|█████████▏| 80000/87599 [00:00<00:00, 255146.46 examples/s]Generating train split: 100%|██████████| 87599/87599 [00:00<00:00, 162042.88 examples/s]
Generating validation split:   0%|          | 0/10570 [00:00<?, ? examples/s]Generating validation split: 100%|██████████| 10570/10570 [00:00<00:00, 163064.43 examples/s]
gpuidx: 0 with rank: 0 with world size: 2
initialized the distributed DNN
gpuidx: 1 with rank: 1 with world size: 2
Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:04<00:28,  4.78s/it]Loading checkpoint shards:  14%|█▍        | 1/7 [00:04<00:29,  4.85s/it]Loading checkpoint shards:  29%|██▊       | 2/7 [00:06<00:13,  2.79s/it]Loading checkpoint shards:  29%|██▊       | 2/7 [00:06<00:14,  2.86s/it]Loading checkpoint shards:  43%|████▎     | 3/7 [00:07<00:08,  2.18s/it]Loading checkpoint shards:  43%|████▎     | 3/7 [00:07<00:08,  2.20s/it]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:09<00:05,  1.90s/it]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:09<00:05,  1.90s/it]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:10<00:03,  1.71s/it]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:10<00:03,  1.69s/it]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:11<00:01,  1.57s/it]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:11<00:01,  1.60s/it]Loading checkpoint shards: 100%|██████████| 7/7 [00:12<00:00,  1.32s/it]Loading checkpoint shards: 100%|██████████| 7/7 [00:12<00:00,  1.80s/it]
Loading checkpoint shards: 100%|██████████| 7/7 [00:12<00:00,  1.31s/it]Loading checkpoint shards: 100%|██████████| 7/7 [00:12<00:00,  1.80s/it]
Wrapping layer 1 / 28 from mlp to fMoE
WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:217: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate_weight = torch.load(f"{weight_path}/layer_{i}_gate.pt").to(gpu_idx)

W0116 14:14:44.703126 3758788 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:217: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate_weight = torch.load(f"{weight_path}/layer_{i}_gate.pt").to(gpu_idx)

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:217: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate_weight = torch.load(f"{weight_path}/layer_{i}_gate.pt").to(gpu_idx)

W0116 14:14:44.960534 3758789 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:217: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate_weight = torch.load(f"{weight_path}/layer_{i}_gate.pt").to(gpu_idx)

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:227: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  up_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_up_proj.pt")

W0116 14:14:46.014608 3758788 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:227: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  up_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_up_proj.pt")

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:228: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  down_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_down_proj.pt")

W0116 14:14:46.067729 3758788 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:228: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  down_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_down_proj.pt")

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:229: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_gate_proj.pt")

W0116 14:14:46.109611 3758788 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:229: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_gate_proj.pt")

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:227: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  up_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_up_proj.pt")

W0116 14:14:47.255719 3758789 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:227: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  up_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_up_proj.pt")

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:228: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  down_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_down_proj.pt")

W0116 14:14:47.307293 3758789 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:228: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  down_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_down_proj.pt")

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:229: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_gate_proj.pt")

W0116 14:14:47.355220 3758789 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:229: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  gate_weight = torch.load(f"{weight_path}/layer_{i}_expert_{idx}_gate_proj.pt")

WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:239: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  shared_expert_weight = torch.load(f"{weight_path}/layer_{i}_shared_experts.pt") # state_dict

W0116 14:14:58.545073 3758788 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:239: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  shared_expert_weight = torch.load(f"{weight_path}/layer_{i}_shared_experts.pt") # state_dict

Wrapping layer 2 / 28 from mlp to fMoE
WARNING:py.warnings:/data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:239: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  shared_expert_weight = torch.load(f"{weight_path}/layer_{i}_shared_experts.pt") # state_dict

W0116 14:14:59.453779 3758789 warnings.py:112] /data/home/wjbang/workspace/pMoE/pMoE/lib/moe_utils.py:239: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  shared_expert_weight = torch.load(f"{weight_path}/layer_{i}_shared_experts.pt") # state_dict

Wrapping layer 3 / 28 from mlp to fMoE
Wrapping layer 4 / 28 from mlp to fMoE
Wrapping layer 5 / 28 from mlp to fMoE
Wrapping layer 6 / 28 from mlp to fMoE
Wrapping layer 7 / 28 from mlp to fMoE
Wrapping layer 8 / 28 from mlp to fMoE
Wrapping layer 9 / 28 from mlp to fMoE
Wrapping layer 10 / 28 from mlp to fMoE
Wrapping layer 11 / 28 from mlp to fMoE
Wrapping layer 12 / 28 from mlp to fMoE
Wrapping layer 13 / 28 from mlp to fMoE
Wrapping layer 14 / 28 from mlp to fMoE
Wrapping layer 15 / 28 from mlp to fMoE
Wrapping layer 16 / 28 from mlp to fMoE
Wrapping layer 17 / 28 from mlp to fMoE
Wrapping layer 18 / 28 from mlp to fMoE
Wrapping layer 19 / 28 from mlp to fMoE
Wrapping layer 20 / 28 from mlp to fMoE
Wrapping layer 21 / 28 from mlp to fMoE
Wrapping layer 22 / 28 from mlp to fMoE
Wrapping layer 23 / 28 from mlp to fMoE
Wrapping layer 24 / 28 from mlp to fMoE
Wrapping layer 25 / 28 from mlp to fMoE
Wrapping layer 26 / 28 from mlp to fMoE
Wrapping layer 27 / 28 from mlp to fMoE
processing 0th data
processing 10th data
processing 20th data
processing 30th data
processing 40th data
processing 50th data
processing 60th data
processing 70th data
processing 80th data
processing 90th data
processing 100th data
processing 110th data
processing 120th data
processing 130th data
processing 140th data
processing 150th data
processing 160th data
processing 170th data
processing 180th data
processing 190th data
processing 200th data
processing 210th data
processing 220th data
processing 230th data
processing 240th data
processing 250th data
processing 260th data
processing 270th data
processing 280th data
processing 290th data
processing 300th data
processing 310th data
processing 320th data
processing 330th data
processing 340th data
processing 350th data
processing 360th data
processing 370th data
processing 380th data
processing 390th data
processing 400th data
processing 410th data
processing 420th data
processing 430th data
processing 440th data
processing 450th data
processing 460th data
processing 470th data
processing 480th data
processing 490th data
processing 500th data
processing 510th data
processing 520th data
processing 530th data
processing 540th data
processing 550th data
processing 560th data
processing 570th data
processing 580th data
processing 590th data
processing 600th data
processing 610th data
processing 620th data
processing 630th data
processing 640th data
processing 650th data
processing 660th data
processing 670th data
processing 680th data
processing 690th data
processing 700th data
processing 710th data
processing 720th data
processing 730th data
processing 740th data
processing 750th data
processing 760th data
processing 770th data
processing 780th data
processing 790th data
processing 800th data
processing 810th data
processing 820th data
processing 830th data
processing 840th data
processing 850th data
processing 860th data
processing 870th data
processing 880th data
processing 890th data
processing 900th data
processing 910th data
processing 920th data
processing 930th data
processing 940th data
processing 950th data
processing 960th data
processing 970th data
processing 980th data
processing 990th data
processing 1000th data
FMOE: [Rank 1] Average Elapsed Time: 255.25199487304687ms 

FMOE: [Rank 0] Average Elapsed Time: 255.23793000793458ms 

